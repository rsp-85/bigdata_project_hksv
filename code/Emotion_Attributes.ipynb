{"cells":[{"cell_type":"code","execution_count":2,"id":"4fcdfd43","metadata":{},"outputs":[{"data":{"text/html":["\n","            <div>\n","                <p><b>SparkSession - hive</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://bigdatacluster2-m.us-central1-a.c.even-hull-328204.internal:39827\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.1.2</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>yarn</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>PySparkShell</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "],"text/plain":["<pyspark.sql.session.SparkSession at 0x7efc7061e550>"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["spark"]},{"cell_type":"code","execution_count":3,"id":"854e9d9d","metadata":{},"outputs":[],"source":["from pyspark.sql import SparkSession\n","from pyspark.sql import functions as F\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","import json\n","import sparknlp\n","from sparknlp.pretrained import PretrainedPipeline"]},{"cell_type":"code","execution_count":4,"id":"8c4e6101","metadata":{},"outputs":[{"data":{"text/plain":["[('spark.eventLog.enabled', 'true'),\n"," ('spark.dynamicAllocation.minExecutors', '1'),\n"," ('spark.ui.proxyBase', '/proxy/application_1638408497775_0002'),\n"," ('spark.yarn.historyServer.address', 'bigdatacluster2-m:18080'),\n"," ('spark.sql.warehouse.dir', 'file:/spark-warehouse'),\n"," ('spark.yarn.dist.jars',\n","  'file:///root/.ivy2/jars/com.johnsnowlabs.nlp_spark-nlp_2.12-3.3.2.jar,file:///root/.ivy2/jars/com.typesafe_config-1.4.1.jar,file:///root/.ivy2/jars/org.rocksdb_rocksdbjni-6.5.3.jar,file:///root/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.11.603.jar,file:///root/.ivy2/jars/com.github.universal-automata_liblevenshtein-3.0.0.jar,file:///root/.ivy2/jars/com.navigamez_greex-1.0.jar,file:///root/.ivy2/jars/org.json4s_json4s-ext_2.12-3.5.3.jar,file:///root/.ivy2/jars/com.johnsnowlabs.nlp_tensorflow-cpu_2.12-0.3.3.jar,file:///root/.ivy2/jars/net.sf.trove4j_trove4j-3.0.3.jar,file:///root/.ivy2/jars/com.google.code.findbugs_annotations-3.0.1.jar,file:///root/.ivy2/jars/com.google.protobuf_protobuf-java-util-3.0.0-beta-3.jar,file:///root/.ivy2/jars/com.google.protobuf_protobuf-java-3.0.0-beta-3.jar,file:///root/.ivy2/jars/it.unimi.dsi_fastutil-7.0.12.jar,file:///root/.ivy2/jars/org.projectlombok_lombok-1.16.8.jar,file:///root/.ivy2/jars/org.slf4j_slf4j-api-1.7.21.jar,file:///root/.ivy2/jars/net.jcip_jcip-annotations-1.0.jar,file:///root/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.1.jar,file:///root/.ivy2/jars/com.google.code.gson_gson-2.3.jar,file:///root/.ivy2/jars/dk.brics.automaton_automaton-1.11-8.jar,file:///root/.ivy2/jars/joda-time_joda-time-2.9.5.jar,file:///root/.ivy2/jars/org.joda_joda-convert-1.8.1.jar'),\n"," ('spark.driver.memory', '3328m'),\n"," ('spark.yarn.am.memory', '640m'),\n"," ('spark.kryoserializer.buffer.max', '2000M'),\n"," ('spark.jars.packages', 'com.johnsnowlabs.nlp:spark-nlp_2.12:3.3.2'),\n"," ('spark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.PROXY_URI_BASES',\n","  'http://bigdatacluster2-m:8088/proxy/application_1638408497775_0002'),\n"," ('spark.sql.autoBroadcastJoinThreshold', '36m'),\n"," ('spark.serializer', 'org.apache.spark.serializer.KryoSerializer'),\n"," ('spark.eventLog.dir',\n","  'gs://dataproc-temp-us-central1-483306255930-3hw1ksoh/ef12d4de-3670-4598-bc21-374ef433c8e4/spark-job-history'),\n"," ('spark.executor.instances', '2'),\n"," ('spark.serializer.objectStreamReset', '100'),\n"," ('spark.driver.maxResultSize', '0'),\n"," ('spark.yarn.unmanagedAM.enabled', 'true'),\n"," ('spark.submit.pyFiles',\n","  '/root/.ivy2/jars/com.johnsnowlabs.nlp_spark-nlp_2.12-3.3.2.jar,/root/.ivy2/jars/com.typesafe_config-1.4.1.jar,/root/.ivy2/jars/org.rocksdb_rocksdbjni-6.5.3.jar,/root/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.11.603.jar,/root/.ivy2/jars/com.github.universal-automata_liblevenshtein-3.0.0.jar,/root/.ivy2/jars/com.navigamez_greex-1.0.jar,/root/.ivy2/jars/org.json4s_json4s-ext_2.12-3.5.3.jar,/root/.ivy2/jars/com.johnsnowlabs.nlp_tensorflow-cpu_2.12-0.3.3.jar,/root/.ivy2/jars/net.sf.trove4j_trove4j-3.0.3.jar,/root/.ivy2/jars/com.google.code.findbugs_annotations-3.0.1.jar,/root/.ivy2/jars/com.google.protobuf_protobuf-java-util-3.0.0-beta-3.jar,/root/.ivy2/jars/com.google.protobuf_protobuf-java-3.0.0-beta-3.jar,/root/.ivy2/jars/it.unimi.dsi_fastutil-7.0.12.jar,/root/.ivy2/jars/org.projectlombok_lombok-1.16.8.jar,/root/.ivy2/jars/org.slf4j_slf4j-api-1.7.21.jar,/root/.ivy2/jars/net.jcip_jcip-annotations-1.0.jar,/root/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.1.jar,/root/.ivy2/jars/com.google.code.gson_gson-2.3.jar,/root/.ivy2/jars/dk.brics.automaton_automaton-1.11-8.jar,/root/.ivy2/jars/joda-time_joda-time-2.9.5.jar,/root/.ivy2/jars/org.joda_joda-convert-1.8.1.jar'),\n"," ('spark.submit.deployMode', 'client'),\n"," ('spark.app.id', 'application_1638408497775_0002'),\n"," ('spark.ui.filters',\n","  'org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter'),\n"," ('spark.app.startTime', '1638409350694'),\n"," ('spark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.PROXY_HOSTS',\n","  'bigdatacluster2-m'),\n"," ('spark.sql.cbo.joinReorder.enabled', 'true'),\n"," ('spark.driver.appUIAddress',\n","  'http://bigdatacluster2-m.us-central1-a.c.even-hull-328204.internal:39827'),\n"," ('spark.shuffle.service.enabled', 'true'),\n"," ('spark.yarn.secondary.jars',\n","  'com.johnsnowlabs.nlp_spark-nlp_2.12-3.3.2.jar,com.typesafe_config-1.4.1.jar,org.rocksdb_rocksdbjni-6.5.3.jar,com.amazonaws_aws-java-sdk-bundle-1.11.603.jar,com.github.universal-automata_liblevenshtein-3.0.0.jar,com.navigamez_greex-1.0.jar,org.json4s_json4s-ext_2.12-3.5.3.jar,com.johnsnowlabs.nlp_tensorflow-cpu_2.12-0.3.3.jar,net.sf.trove4j_trove4j-3.0.3.jar,com.google.code.findbugs_annotations-3.0.1.jar,com.google.protobuf_protobuf-java-util-3.0.0-beta-3.jar,com.google.protobuf_protobuf-java-3.0.0-beta-3.jar,it.unimi.dsi_fastutil-7.0.12.jar,org.projectlombok_lombok-1.16.8.jar,org.slf4j_slf4j-api-1.7.21.jar,net.jcip_jcip-annotations-1.0.jar,com.google.code.findbugs_jsr305-3.0.1.jar,com.google.code.gson_gson-2.3.jar,dk.brics.automaton_automaton-1.11-8.jar,joda-time_joda-time-2.9.5.jar,org.joda_joda-convert-1.8.1.jar'),\n"," ('spark.scheduler.mode', 'FAIR'),\n"," ('spark.repl.local.jars',\n","  'file:///root/.ivy2/jars/com.johnsnowlabs.nlp_spark-nlp_2.12-3.3.2.jar,file:///root/.ivy2/jars/com.typesafe_config-1.4.1.jar,file:///root/.ivy2/jars/org.rocksdb_rocksdbjni-6.5.3.jar,file:///root/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.11.603.jar,file:///root/.ivy2/jars/com.github.universal-automata_liblevenshtein-3.0.0.jar,file:///root/.ivy2/jars/com.navigamez_greex-1.0.jar,file:///root/.ivy2/jars/org.json4s_json4s-ext_2.12-3.5.3.jar,file:///root/.ivy2/jars/com.johnsnowlabs.nlp_tensorflow-cpu_2.12-0.3.3.jar,file:///root/.ivy2/jars/net.sf.trove4j_trove4j-3.0.3.jar,file:///root/.ivy2/jars/com.google.code.findbugs_annotations-3.0.1.jar,file:///root/.ivy2/jars/com.google.protobuf_protobuf-java-util-3.0.0-beta-3.jar,file:///root/.ivy2/jars/com.google.protobuf_protobuf-java-3.0.0-beta-3.jar,file:///root/.ivy2/jars/it.unimi.dsi_fastutil-7.0.12.jar,file:///root/.ivy2/jars/org.projectlombok_lombok-1.16.8.jar,file:///root/.ivy2/jars/org.slf4j_slf4j-api-1.7.21.jar,file:///root/.ivy2/jars/net.jcip_jcip-annotations-1.0.jar,file:///root/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.1.jar,file:///root/.ivy2/jars/com.google.code.gson_gson-2.3.jar,file:///root/.ivy2/jars/dk.brics.automaton_automaton-1.11-8.jar,file:///root/.ivy2/jars/joda-time_joda-time-2.9.5.jar,file:///root/.ivy2/jars/org.joda_joda-convert-1.8.1.jar'),\n"," ('spark.sql.adaptive.enabled', 'true'),\n"," ('spark.yarn.jars', 'local:/usr/lib/spark/jars/*'),\n"," ('spark.scheduler.minRegisteredResourcesRatio', '0.0'),\n"," ('spark.executor.id', 'driver'),\n"," ('spark.hadoop.hive.execution.engine', 'mr'),\n"," ('spark.yarn.dist.pyFiles',\n","  'file:///root/.ivy2/jars/com.johnsnowlabs.nlp_spark-nlp_2.12-3.3.2.jar,file:///root/.ivy2/jars/com.typesafe_config-1.4.1.jar,file:///root/.ivy2/jars/org.rocksdb_rocksdbjni-6.5.3.jar,file:///root/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.11.603.jar,file:///root/.ivy2/jars/com.github.universal-automata_liblevenshtein-3.0.0.jar,file:///root/.ivy2/jars/com.navigamez_greex-1.0.jar,file:///root/.ivy2/jars/org.json4s_json4s-ext_2.12-3.5.3.jar,file:///root/.ivy2/jars/com.johnsnowlabs.nlp_tensorflow-cpu_2.12-0.3.3.jar,file:///root/.ivy2/jars/net.sf.trove4j_trove4j-3.0.3.jar,file:///root/.ivy2/jars/com.google.code.findbugs_annotations-3.0.1.jar,file:///root/.ivy2/jars/com.google.protobuf_protobuf-java-util-3.0.0-beta-3.jar,file:///root/.ivy2/jars/com.google.protobuf_protobuf-java-3.0.0-beta-3.jar,file:///root/.ivy2/jars/it.unimi.dsi_fastutil-7.0.12.jar,file:///root/.ivy2/jars/org.projectlombok_lombok-1.16.8.jar,file:///root/.ivy2/jars/org.slf4j_slf4j-api-1.7.21.jar,file:///root/.ivy2/jars/net.jcip_jcip-annotations-1.0.jar,file:///root/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.1.jar,file:///root/.ivy2/jars/com.google.code.gson_gson-2.3.jar,file:///root/.ivy2/jars/dk.brics.automaton_automaton-1.11-8.jar,file:///root/.ivy2/jars/joda-time_joda-time-2.9.5.jar,file:///root/.ivy2/jars/org.joda_joda-convert-1.8.1.jar'),\n"," ('spark.app.name', 'PySparkShell'),\n"," ('spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version', '2'),\n"," ('spark.dynamicAllocation.maxExecutors', '10000'),\n"," ('spark.master', 'yarn'),\n"," ('spark.ui.port', '0'),\n"," ('spark.sql.catalogImplementation', 'hive'),\n"," ('spark.rpc.message.maxSize', '512'),\n"," ('spark.rdd.compress', 'True'),\n"," ('spark.executorEnv.PYTHONPATH',\n","  '/usr/lib/spark/python/lib/py4j-0.10.9-src.zip:/usr/lib/spark/python/:<CPS>{{PWD}}/pyspark.zip<CPS>{{PWD}}/py4j-0.10.9-src.zip<CPS>{{PWD}}/com.johnsnowlabs.nlp_spark-nlp_2.12-3.3.2.jar<CPS>{{PWD}}/com.typesafe_config-1.4.1.jar<CPS>{{PWD}}/org.rocksdb_rocksdbjni-6.5.3.jar<CPS>{{PWD}}/com.amazonaws_aws-java-sdk-bundle-1.11.603.jar<CPS>{{PWD}}/com.github.universal-automata_liblevenshtein-3.0.0.jar<CPS>{{PWD}}/com.navigamez_greex-1.0.jar<CPS>{{PWD}}/org.json4s_json4s-ext_2.12-3.5.3.jar<CPS>{{PWD}}/com.johnsnowlabs.nlp_tensorflow-cpu_2.12-0.3.3.jar<CPS>{{PWD}}/net.sf.trove4j_trove4j-3.0.3.jar<CPS>{{PWD}}/com.google.code.findbugs_annotations-3.0.1.jar<CPS>{{PWD}}/com.google.protobuf_protobuf-java-util-3.0.0-beta-3.jar<CPS>{{PWD}}/com.google.protobuf_protobuf-java-3.0.0-beta-3.jar<CPS>{{PWD}}/it.unimi.dsi_fastutil-7.0.12.jar<CPS>{{PWD}}/org.projectlombok_lombok-1.16.8.jar<CPS>{{PWD}}/org.slf4j_slf4j-api-1.7.21.jar<CPS>{{PWD}}/net.jcip_jcip-annotations-1.0.jar<CPS>{{PWD}}/com.google.code.findbugs_jsr305-3.0.1.jar<CPS>{{PWD}}/com.google.code.gson_gson-2.3.jar<CPS>{{PWD}}/dk.brics.automaton_automaton-1.11-8.jar<CPS>{{PWD}}/joda-time_joda-time-2.9.5.jar<CPS>{{PWD}}/org.joda_joda-convert-1.8.1.jar'),\n"," ('spark.executor.memory', '4900m'),\n"," ('spark.dynamicAllocation.enabled', 'true'),\n"," ('spark.history.fs.gs.outputstream.type', 'BASIC'),\n"," ('spark.driver.host',\n","  'bigdatacluster2-m.us-central1-a.c.even-hull-328204.internal'),\n"," ('spark.yarn.isPython', 'true'),\n"," ('spark.history.fs.logDirectory',\n","  'gs://dataproc-temp-us-central1-483306255930-3hw1ksoh/ef12d4de-3670-4598-bc21-374ef433c8e4/spark-job-history'),\n"," ('spark.executor.cores', '1'),\n"," ('spark.ui.showConsoleProgress', 'true'),\n"," ('spark.driver.port', '38355'),\n"," ('spark.executorEnv.OPENBLAS_NUM_THREADS', '1'),\n"," ('spark.sql.cbo.enabled', 'true')]"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["spark = SparkSession.builder.appName('TwitterCovid19_EmotionAttributes').getOrCreate()\n","\n","#change configuration settings on Spark \n","#conf = spark.sparkContext._conf.setAll([('spark.executor.memory', '5g'), ('spark.app.name', 'Spark Updated Conf'), ('spark.executor.cores', '4'), ('spark.cores.max', '4'), ('spark.driver.memory','8g')])\n","\n","#print spark configuration settings\n","spark.sparkContext.getConf().getAll()"]},{"cell_type":"code","execution_count":5,"id":"d9957c91","metadata":{},"outputs":[{"data":{"text/html":["\n","            <div>\n","                <p><b>SparkSession - hive</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://bigdatacluster2-m.us-central1-a.c.even-hull-328204.internal:39827\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.1.2</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>yarn</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>PySparkShell</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "],"text/plain":["<pyspark.sql.session.SparkSession at 0x7efc7061e550>"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["sparknlp.start()"]},{"cell_type":"code","execution_count":6,"id":"ab8c1ff0","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["21/12/02 02:17:12 WARN org.apache.hadoop.util.concurrent.ExecutorHelper: Thread (Thread[GetFileInfo #9,5,main]) interrupted: \n","java.lang.InterruptedException\n","\tat com.google.common.util.concurrent.AbstractFuture.get(AbstractFuture.java:510)\n","\tat com.google.common.util.concurrent.FluentFuture$TrustedFuture.get(FluentFuture.java:88)\n","\tat org.apache.hadoop.util.concurrent.ExecutorHelper.logThrowableFromAfterExecute(ExecutorHelper.java:48)\n","\tat org.apache.hadoop.util.concurrent.HadoopThreadPoolExecutor.afterExecute(HadoopThreadPoolExecutor.java:90)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1157)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:748)\n","21/12/02 02:17:12 WARN org.apache.hadoop.util.concurrent.ExecutorHelper: Thread (Thread[GetFileInfo #8,5,main]) interrupted: \n","java.lang.InterruptedException\n","\tat com.google.common.util.concurrent.AbstractFuture.get(AbstractFuture.java:510)\n","\tat com.google.common.util.concurrent.FluentFuture$TrustedFuture.get(FluentFuture.java:88)\n","\tat org.apache.hadoop.util.concurrent.ExecutorHelper.logThrowableFromAfterExecute(ExecutorHelper.java:48)\n","\tat org.apache.hadoop.util.concurrent.HadoopThreadPoolExecutor.afterExecute(HadoopThreadPoolExecutor.java:90)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1157)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:748)\n","                                                                                \r"]}],"source":["df = spark.read.option(\"multiline\",\"true\") \\\n","    .option(\"header\", \"true\") \\\n","    .option(\"inferSchema\", \"true\") \\\n","    .option(\"ignoreTrailingWhiteSpace\",\"true\") \\\n","    .option(\"ignoreLeadingWhiteSpace\", \"true\") \\\n","    .option(\"escapechar\", \"\\n\") \\\n","    .option('escape','\"') \\\n","    .csv(\"gs://bigdata_project_hksv/tweetData/*.csv\")"]},{"cell_type":"code","execution_count":7,"id":"7025570e","metadata":{},"outputs":[{"data":{"text/plain":["DataFrame[tweet_id: bigint, tdate: string, ttime: string, tlang: string, tcountry_place: string, month_year: string, tweet: string]"]},"metadata":{},"output_type":"display_data"}],"source":["df1 = df.dropna(thresh=1, subset=('tweet'))\n","display(df1)"]},{"cell_type":"code","execution_count":8,"id":"90c64ee0","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 2:>                                                          (0 + 1) / 1]\r"]},{"name":"stdout","output_type":"stream","text":["+-------------------+----------+--------+-----+--------------+----------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","|tweet_id           |tdate     |ttime   |tlang|tcountry_place|month_year|tweet                                                                                                                                                                                                                                                                                     |\n","+-------------------+----------+--------+-----+--------------+----------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","|1292160311273947136|2020-08-08|18:06:40|en   |NULL          |2020-08   |Democrats say COVID19 is really really really really really really really bad! Then blame the President for everything like a little kid would do on the playground during recess.                                                                                                        |\n","|1292160314889457673|2020-08-08|18:06:40|en   |NULL          |2020-08   |COVID-stricken Anchorage wins court ruling in diner dispute https://t.co/91xgRjxanl                                                                                                                                                                                                       |\n","|1292160315027849217|2020-08-08|18:06:40|en   |NULL          |2020-08   |Did I happen to mention that I absolutely hate #COVID19? #notfun #faceshieldselfies https://t.co/f9G1ROXZRI                                                                                                                                                                               |\n","|1292160317867335680|2020-08-08|18:06:41|en   |NULL          |2020-08   |Georgia School Lifts Suspension of Student Who Posted Hallway Pic Showing COVID Risk via @TMZ https://t.co/QXb6fy3YWF https://t.co/0rxPoKNY3h                                                                                                                                             |\n","|1292160318743949313|2020-08-08|18:06:41|en   |NULL          |2020-08   |Brazil now has 100,000 deaths by Covid-19.\n","\n","One hundred thousand deaths.\n","\n","And that is an underestimated count. And we are still in the peak, with +1,000 death/day. https://t.co/WcrOpfYStn                                                                                               |\n","|1292160319171657730|2020-08-08|18:06:41|en   |NULL          |2020-08   |For all the hemming and hawing about metrics(cases, per capita, infection rates), this is what really matters and there is no truthful way you can look at these numbers and say â€œwe are doing wellâ€ https://t.co/ud1LrULLQP                                                              |\n","|1292160320463667200|2020-08-08|18:06:42|en   |NULL          |2020-08   |97,000 children reportedly test positive for coronavirus in two weeks as schools gear up for instruction - CBS News https://t.co/fTXfP2wQeI                                                                                                                                               |\n","|1292160320514019330|2020-08-08|18:06:42|en   |NULL          |2020-08   |@realDonaldTrump @stevenmnuchin1 @LindseyGrahamSC  What about the $1,200.00 second COVID-19 Stimulus check why isn't that mentioned on WH Executive Action; to help struggling seniors, poor unemployed ineligible for benefits,, poor disabled, farmers etc who VOTED &amp; supported you|\n","|1292160321193480193|2020-08-08|18:06:42|en   |NULL          |2020-08   |Historic 'wine windows' used by vintners in Tuscany during plague 400 years ago come back into use during coronavirus https://t.co/5zowq6UVnh                                                                                                                                             |\n","|1292160326520188929|2020-08-08|18:06:43|en   |NULL          |2020-08   |New way to practice â€œhotâ€ yoga https://t.co/kfgiQESoPo                                                                                                                                                                                                                                    |\n","|1292160326729834496|2020-08-08|18:06:43|en   |NULL          |2020-08   |Yes. Pls bring jaadu back. Only he and Krrish can help make an antidote of this #coronavirus.\n","\n","@iHrithik #KoiMilGaya https://t.co/O6favBBv8k                                                                                                                                              |\n","|1292160326847193090|2020-08-08|18:06:43|en   |NULL          |2020-08   |Health care workers in hospitals wear masks all day! Caring for covid19 victims. Saving lives. Show some love ðŸ’ž #WearAMask ðŸ˜·. #JoeBiden2020 https://t.co/SVTKB88rBc                                                                                                                     |\n","|1292160326998413315|2020-08-08|18:06:43|en   |NULL          |2020-08   |#MaskOnPakistan to reduce the risk of spreading #COVID19 to others around you.\n","\n","#TakeResponsibility! Please #WearAMask today as you practice other #COVID19 preventive measures.\n","\n","MASK UP!\n","STAY SAFE!!\n","STAY HEALTHY!!!\n","\n","It's #WorldMaskWeek2020.ðŸ˜· https://t.co/0vnPxfrAZm                |\n","|1292160327639949312|2020-08-08|18:06:43|en   |NULL          |2020-08   |Retract this. Take it off your website with a note saying \"we were wrong.\" @washingtonpost https://t.co/crSIX2k1zI                                                                                                                                                                        |\n","|1292160327870640128|2020-08-08|18:06:43|en   |NULL          |2020-08   |Candidates for Darwin.  The virus doesn't care about opinions. https://t.co/1hOTbipVZJ                                                                                                                                                                                                    |\n","|1292160328072134656|2020-08-08|18:06:44|en   |NULL          |2020-08   |When you tweet for the first time in ages and feel like it should bang and it doesnâ€™tðŸ˜¢ https://t.co/XGl7gB9KUH                                                                                                                                                                           |\n","|1292160328294424576|2020-08-08|18:06:44|en   |NULL          |2020-08   |Zimbabwe health minister facing coronavirus corruption charge sacked https://t.co/jeMFaJIIFI                                                                                                                                                                                              |\n","|1292160331905667073|2020-08-08|18:06:44|en   |NULL          |2020-08   |well well https://t.co/F87zJXEIiJ                                                                                                                                                                                                                                                         |\n","|1292160332778086400|2020-08-08|18:06:45|en   |NULL          |2020-08   |He's just telling it like it is.  The fact that he receives death threats for giving us medical advice is abhorrent. #DrFauci is on our side! https://t.co/qXyLiFt9xZ                                                                                                                     |\n","|1292160333302378498|2020-08-08|18:06:45|en   |NULL          |2020-08   |SCOTLAND.  \n","\n","Coronavirus (COVID-19): daily data for Scotland. 8 August 2020.\n","\n","0 new reported death(s) of people who have tested positive.\n","\n","Scotland's death toll 2,491.\n","\n","#coronavirus disease 2019 (COVID-19) #COVID19  #Scotland https://t.co/tGeuY4EFXH                                 |\n","+-------------------+----------+--------+-----+--------------+----------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","only showing top 20 rows\n","\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["df1.show(truncate = False)"]},{"cell_type":"code","execution_count":9,"id":"fc7fa00b","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+-------------------+----------+--------+-----+--------------+----------+--------------------+\n","|           tweet_id|     tdate|   ttime|tlang|tcountry_place|month_year|               tweet|\n","+-------------------+----------+--------+-----+--------------+----------+--------------------+\n","|1292160311273947136|2020-08-08|18:06:40|   en|          NULL|   2020-08|Democrats say COV...|\n","|1292160314889457673|2020-08-08|18:06:40|   en|          NULL|   2020-08|COVID-stricken An...|\n","|1292160315027849217|2020-08-08|18:06:40|   en|          NULL|   2020-08|Did I happen to m...|\n","|1292160317867335680|2020-08-08|18:06:41|   en|          NULL|   2020-08|Georgia School Li...|\n","|1292160318743949313|2020-08-08|18:06:41|   en|          NULL|   2020-08|Brazil now has 10...|\n","|1292160319171657730|2020-08-08|18:06:41|   en|          NULL|   2020-08|For all the hemmi...|\n","|1292160320463667200|2020-08-08|18:06:42|   en|          NULL|   2020-08|97,000 children r...|\n","|1292160320514019330|2020-08-08|18:06:42|   en|          NULL|   2020-08|@realDonaldTrump ...|\n","|1292160321193480193|2020-08-08|18:06:42|   en|          NULL|   2020-08|Historic 'wine wi...|\n","|1292160326520188929|2020-08-08|18:06:43|   en|          NULL|   2020-08|New way to practi...|\n","|1292160326729834496|2020-08-08|18:06:43|   en|          NULL|   2020-08|Yes. Pls bring ja...|\n","|1292160326847193090|2020-08-08|18:06:43|   en|          NULL|   2020-08|Health care worke...|\n","|1292160326998413315|2020-08-08|18:06:43|   en|          NULL|   2020-08|#MaskOnPakistan t...|\n","|1292160327639949312|2020-08-08|18:06:43|   en|          NULL|   2020-08|Retract this. Tak...|\n","|1292160327870640128|2020-08-08|18:06:43|   en|          NULL|   2020-08|Candidates for Da...|\n","|1292160328072134656|2020-08-08|18:06:44|   en|          NULL|   2020-08|When you tweet fo...|\n","|1292160328294424576|2020-08-08|18:06:44|   en|          NULL|   2020-08|Zimbabwe health m...|\n","|1292160331905667073|2020-08-08|18:06:44|   en|          NULL|   2020-08|well well https:/...|\n","|1292160332778086400|2020-08-08|18:06:45|   en|          NULL|   2020-08|He's just telling...|\n","|1292160333302378498|2020-08-08|18:06:45|   en|          NULL|   2020-08|SCOTLAND.  \n","\n","Coro...|\n","+-------------------+----------+--------+-----+--------------+----------+--------------------+\n","only showing top 20 rows\n","\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["df1 = df1.filter(df1.tlang == \"en\")\n","df1.show()"]},{"cell_type":"code","execution_count":10,"id":"1e045467","metadata":{},"outputs":[],"source":["from pyspark.ml.feature import Tokenizer, RegexTokenizer\n","from pyspark.sql.functions import regexp_replace, col\n","from pyspark.sql.functions import col, udf\n","from pyspark.sql.types import IntegerType"]},{"cell_type":"code","execution_count":11,"id":"9b865af8","metadata":{},"outputs":[],"source":["def preprocessing(lines):\n","    words = lines.select(explode(split(lines.value, \"t_end\")).alias(\"word\"))\n","    words = words.na.replace('', None)\n","    words = words.na.drop()\n","    words = words.withColumn('word', F.regexp_replace('word', r'http\\S+', ''))\n","    words = words.withColumn('word', F.regexp_replace('word', '@\\w+', ''))\n","    words = words.withColumn('word', F.regexp_replace('word', '#', ''))\n","    words = words.withColumn('word', F.regexp_replace('word', 'RT', ''))\n","    words = words.withColumn('word', F.regexp_replace('word', ':', ''))\n","    return words"]},{"cell_type":"code","execution_count":12,"id":"57b382cb","metadata":{},"outputs":[],"source":["df2 = df1.withColumn('tweet1',regexp_replace(col('tweet'), '@', ''))\n","df2 = df2.withColumn('tweet2',regexp_replace(col('tweet1'), '#', ''))\n","df2 = df2.withColumn('tweet2',regexp_replace(col('tweet2'), 'RT', ''))\n","df2 = df2.withColumn('tweet2',regexp_replace(col('tweet2'), ':', ''))\n","df2 = df2.withColumn('tweet2',regexp_replace(col('tweet2'), 'http\\S+', ''))"]},{"cell_type":"code","execution_count":13,"id":"2a08a120","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","|tweet2                                                                                                                                                                                                                                                                                 |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","|Democrats say COVID19 is really really really really really really really bad! Then blame the President for everything like a little kid would do on the playground during recess.                                                                                                     |\n","|COVID-stricken Anchorage wins court ruling in diner dispute                                                                                                                                                                                                                            |\n","|Did I happen to mention that I absolutely hate COVID19? notfun faceshieldselfies                                                                                                                                                                                                       |\n","|Georgia School Lifts Suspension of Student Who Posted Hallway Pic Showing COVID Risk via TMZ                                                                                                                                                                                           |\n","|Brazil now has 100,000 deaths by Covid-19.\n","\n","One hundred thousand deaths.\n","\n","And that is an underestimated count. And we are still in the peak, with +1,000 death/day.                                                                                                                    |\n","|For all the hemming and hawing about metrics(cases, per capita, infection rates), this is what really matters and there is no truthful way you can look at these numbers and say â€œwe are doing wellâ€                                                                                   |\n","|97,000 children reportedly test positive for coronavirus in two weeks as schools gear up for instruction - CBS News                                                                                                                                                                    |\n","|realDonaldTrump stevenmnuchin1 LindseyGrahamSC  What about the $1,200.00 second COVID-19 Stimulus check why isn't that mentioned on WH Executive Action; to help struggling seniors, poor unemployed ineligible for benefits,, poor disabled, farmers etc who VOTED &amp; supported you|\n","|Historic 'wine windows' used by vintners in Tuscany during plague 400 years ago come back into use during coronavirus                                                                                                                                                                  |\n","|New way to practice â€œhotâ€ yoga                                                                                                                                                                                                                                                         |\n","|Yes. Pls bring jaadu back. Only he and Krrish can help make an antidote of this coronavirus.\n","\n","iHrithik KoiMilGaya                                                                                                                                                                      |\n","|Health care workers in hospitals wear masks all day! Caring for covid19 victims. Saving lives. Show some love ðŸ’ž WearAMask ðŸ˜·. JoeBiden2020                                                                                                                                            |\n","|MaskOnPakistan to reduce the risk of spreading COVID19 to others around you.\n","\n","TakeResponsibility! Please WearAMask today as you practice other COVID19 preventive measures.\n","\n","MASK UP!\n","STAY SAFE!!\n","STAY HEALTHY!!!\n","\n","It's WorldMaskWeek2020.ðŸ˜·                                           |\n","|Retract this. Take it off your website with a note saying \"we were wrong.\" washingtonpost                                                                                                                                                                                              |\n","|Candidates for Darwin.  The virus doesn't care about opinions.                                                                                                                                                                                                                         |\n","|When you tweet for the first time in ages and feel like it should bang and it doesnâ€™tðŸ˜¢                                                                                                                                                                                                |\n","|Zimbabwe health minister facing coronavirus corruption charge sacked                                                                                                                                                                                                                   |\n","|well well                                                                                                                                                                                                                                                                              |\n","|He's just telling it like it is.  The fact that he receives death threats for giving us medical advice is abhorrent. DrFauci is on our side!                                                                                                                                           |\n","|SCOTLAND.  \n","\n","Coronavirus (COVID-19) daily data for Scotland. 8 August 2020.\n","\n","0 new reported death(s) of people who have tested positive.\n","\n","Scotland's death toll 2,491.\n","\n","coronavirus disease 2019 (COVID-19) COVID19  Scotland                                                          |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","only showing top 20 rows\n","\n"]}],"source":["df2.select(col('tweet2')).show(truncate=False)"]},{"cell_type":"code","execution_count":14,"id":"545f60f3","metadata":{},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import json\n","from pyspark.ml import Pipeline\n","from pyspark.sql import SparkSession\n","import pyspark.sql.functions as F\n","from sparknlp.annotator import *\n","from sparknlp.base import *\n","import sparknlp\n","from sparknlp.pretrained import PretrainedPipeline"]},{"cell_type":"code","execution_count":15,"id":"de51204c","metadata":{},"outputs":[],"source":["model_name = 'classifierdl_use_emotion'"]},{"cell_type":"code","execution_count":16,"id":"6be83f34","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tfhub_use download started this may take some time.\n","Approximate size to download 923.7 MB\n","[ | ]tfhub_use download started this may take some time.\n","Approximate size to download 923.7 MB\n","Download done! Loading the resource.\n","[ / ]"]},{"name":"stderr","output_type":"stream","text":["[Stage 5:>                                                          (0 + 1) / 1]\r"]},{"name":"stdout","output_type":"stream","text":["[ â€” ]"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["[ â€” ]"]},{"name":"stderr","output_type":"stream","text":["21/12/02 02:19:35 WARN org.apache.hadoop.hdfs.client.impl.BlockReaderFactory: I/O error constructing remote block reader.\n","java.net.SocketTimeoutException: 60000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.128.15.222:35662 remote=/10.128.15.221:9866]\n","\tat org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)\n","\tat org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)\n","\tat org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)\n","\tat org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:118)\n","\tat java.io.FilterInputStream.read(FilterInputStream.java:83)\n","\tat org.apache.hadoop.hdfs.protocolPB.PBHelperClient.vintPrefixed(PBHelperClient.java:549)\n","\tat org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.newBlockReader(BlockReaderRemote.java:407)\n","\tat org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReader(BlockReaderFactory.java:855)\n","\tat org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:751)\n","\tat org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:381)\n","\tat org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:733)\n","\tat org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:664)\n","\tat org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:849)\n","\tat org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:921)\n","\tat java.io.DataInputStream.read(DataInputStream.java:100)\n","\tat org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:100)\n","\tat org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:68)\n","\tat org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:129)\n","\tat org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:420)\n","\tat org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:392)\n","\tat org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:342)\n","\tat org.apache.hadoop.fs.FileSystem.copyToLocalFile(FileSystem.java:2464)\n","\tat org.apache.hadoop.fs.FileSystem.copyToLocalFile(FileSystem.java:2433)\n","\tat org.apache.hadoop.fs.FileSystem.copyToLocalFile(FileSystem.java:2409)\n","\tat com.johnsnowlabs.ml.tensorflow.ReadTensorflowModel.readTensorflowWithSPModel(TensorflowSerializeModel.scala:176)\n","\tat com.johnsnowlabs.ml.tensorflow.ReadTensorflowModel.readTensorflowWithSPModel$(TensorflowSerializeModel.scala:153)\n","\tat com.johnsnowlabs.nlp.embeddings.UniversalSentenceEncoder$.readTensorflowWithSPModel(UniversalSentenceEncoder.scala:310)\n","\tat com.johnsnowlabs.nlp.embeddings.ReadUSETensorflowModel.readTensorflow(UniversalSentenceEncoder.scala:281)\n","\tat com.johnsnowlabs.nlp.embeddings.ReadUSETensorflowModel.readTensorflow$(UniversalSentenceEncoder.scala:279)\n","\tat com.johnsnowlabs.nlp.embeddings.UniversalSentenceEncoder$.readTensorflow(UniversalSentenceEncoder.scala:310)\n","\tat com.johnsnowlabs.nlp.embeddings.ReadUSETensorflowModel.$anonfun$$init$$1(UniversalSentenceEncoder.scala:285)\n","\tat com.johnsnowlabs.nlp.embeddings.ReadUSETensorflowModel.$anonfun$$init$$1$adapted(UniversalSentenceEncoder.scala:285)\n","\tat com.johnsnowlabs.nlp.ParamsAndFeaturesReadable.$anonfun$onRead$1(ParamsAndFeaturesReadable.scala:47)\n","\tat com.johnsnowlabs.nlp.ParamsAndFeaturesReadable.$anonfun$onRead$1$adapted(ParamsAndFeaturesReadable.scala:46)\n","\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n","\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n","\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n","\tat com.johnsnowlabs.nlp.ParamsAndFeaturesReadable.onRead(ParamsAndFeaturesReadable.scala:46)\n","\tat com.johnsnowlabs.nlp.ParamsAndFeaturesReadable.$anonfun$read$1(ParamsAndFeaturesReadable.scala:57)\n","\tat com.johnsnowlabs.nlp.ParamsAndFeaturesReadable.$anonfun$read$1$adapted(ParamsAndFeaturesReadable.scala:57)\n","\tat com.johnsnowlabs.nlp.FeaturesReader.load(ParamsAndFeaturesReadable.scala:35)\n","\tat com.johnsnowlabs.nlp.FeaturesReader.load(ParamsAndFeaturesReadable.scala:24)\n","\tat com.johnsnowlabs.nlp.pretrained.ResourceDownloader$.downloadModel(ResourceDownloader.scala:406)\n","\tat com.johnsnowlabs.nlp.pretrained.ResourceDownloader$.downloadModel(ResourceDownloader.scala:400)\n","\tat com.johnsnowlabs.nlp.pretrained.PythonResourceDownloader$.downloadModel(ResourceDownloader.scala:536)\n","\tat com.johnsnowlabs.nlp.pretrained.PythonResourceDownloader.downloadModel(ResourceDownloader.scala)\n","\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n","\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n","\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n","\tat java.lang.reflect.Method.invoke(Method.java:498)\n","\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n","\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n","\tat py4j.Gateway.invoke(Gateway.java:282)\n","\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n","\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n","\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n","\tat java.lang.Thread.run(Thread.java:748)\n","21/12/02 02:19:35 WARN org.apache.hadoop.hdfs.DFSClient: Failed to connect to /10.128.15.221:9866 for file /user/root/cache_pretrained/tfhub_use_en_2.4.0_2.4_1587136330099/use_tensorflow for block BP-815815583-10.128.15.222-1638396872943:blk_1073741860_1036, add to deadNodes and continue. \n","java.net.SocketTimeoutException: 60000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.128.15.222:35662 remote=/10.128.15.221:9866]\n","\tat org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)\n","\tat org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)\n","\tat org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)\n","\tat org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:118)\n","\tat java.io.FilterInputStream.read(FilterInputStream.java:83)\n","\tat org.apache.hadoop.hdfs.protocolPB.PBHelperClient.vintPrefixed(PBHelperClient.java:549)\n","\tat org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.newBlockReader(BlockReaderRemote.java:407)\n","\tat org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReader(BlockReaderFactory.java:855)\n","\tat org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:751)\n","\tat org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:381)\n","\tat org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:733)\n","\tat org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:664)\n","\tat org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:849)\n","\tat org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:921)\n","\tat java.io.DataInputStream.read(DataInputStream.java:100)\n","\tat org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:100)\n","\tat org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:68)\n","\tat org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:129)\n","\tat org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:420)\n","\tat org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:392)\n","\tat org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:342)\n","\tat org.apache.hadoop.fs.FileSystem.copyToLocalFile(FileSystem.java:2464)\n","\tat org.apache.hadoop.fs.FileSystem.copyToLocalFile(FileSystem.java:2433)\n","\tat org.apache.hadoop.fs.FileSystem.copyToLocalFile(FileSystem.java:2409)\n","\tat com.johnsnowlabs.ml.tensorflow.ReadTensorflowModel.readTensorflowWithSPModel(TensorflowSerializeModel.scala:176)\n","\tat com.johnsnowlabs.ml.tensorflow.ReadTensorflowModel.readTensorflowWithSPModel$(TensorflowSerializeModel.scala:153)\n","\tat com.johnsnowlabs.nlp.embeddings.UniversalSentenceEncoder$.readTensorflowWithSPModel(UniversalSentenceEncoder.scala:310)\n","\tat com.johnsnowlabs.nlp.embeddings.ReadUSETensorflowModel.readTensorflow(UniversalSentenceEncoder.scala:281)\n","\tat com.johnsnowlabs.nlp.embeddings.ReadUSETensorflowModel.readTensorflow$(UniversalSentenceEncoder.scala:279)\n","\tat com.johnsnowlabs.nlp.embeddings.UniversalSentenceEncoder$.readTensorflow(UniversalSentenceEncoder.scala:310)\n","\tat com.johnsnowlabs.nlp.embeddings.ReadUSETensorflowModel.$anonfun$$init$$1(UniversalSentenceEncoder.scala:285)\n","\tat com.johnsnowlabs.nlp.embeddings.ReadUSETensorflowModel.$anonfun$$init$$1$adapted(UniversalSentenceEncoder.scala:285)\n","\tat com.johnsnowlabs.nlp.ParamsAndFeaturesReadable.$anonfun$onRead$1(ParamsAndFeaturesReadable.scala:47)\n","\tat com.johnsnowlabs.nlp.ParamsAndFeaturesReadable.$anonfun$onRead$1$adapted(ParamsAndFeaturesReadable.scala:46)\n","\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n","\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n","\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n","\tat com.johnsnowlabs.nlp.ParamsAndFeaturesReadable.onRead(ParamsAndFeaturesReadable.scala:46)\n","\tat com.johnsnowlabs.nlp.ParamsAndFeaturesReadable.$anonfun$read$1(ParamsAndFeaturesReadable.scala:57)\n","\tat com.johnsnowlabs.nlp.ParamsAndFeaturesReadable.$anonfun$read$1$adapted(ParamsAndFeaturesReadable.scala:57)\n","\tat com.johnsnowlabs.nlp.FeaturesReader.load(ParamsAndFeaturesReadable.scala:35)\n","\tat com.johnsnowlabs.nlp.FeaturesReader.load(ParamsAndFeaturesReadable.scala:24)\n","\tat com.johnsnowlabs.nlp.pretrained.ResourceDownloader$.downloadModel(ResourceDownloader.scala:406)\n","\tat com.johnsnowlabs.nlp.pretrained.ResourceDownloader$.downloadModel(ResourceDownloader.scala:400)\n","\tat com.johnsnowlabs.nlp.pretrained.PythonResourceDownloader$.downloadModel(ResourceDownloader.scala:536)\n","\tat com.johnsnowlabs.nlp.pretrained.PythonResourceDownloader.downloadModel(ResourceDownloader.scala)\n","\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n","\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n","\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n","\tat java.lang.reflect.Method.invoke(Method.java:498)\n","\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n","\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n","\tat py4j.Gateway.invoke(Gateway.java:282)\n","\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n","\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n","\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n","\tat java.lang.Thread.run(Thread.java:748)\n"]},{"name":"stdout","output_type":"stream","text":["[OK!]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001B[0;31m---------------------------------------------------------------------------\u001B[0m","\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)","\u001B[0;32m/tmp/ipykernel_4108/428646314.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      3\u001B[0m     \u001B[0;34m.\u001B[0m\u001B[0msetOutputCol\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"document\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 5\u001B[0;31m \u001B[0muse\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mUniversalSentenceEncoder\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpretrained\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"tfhub_use\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlang\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"en\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;31m\\\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      6\u001B[0m  \u001B[0;34m.\u001B[0m\u001B[0msetInputCols\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"document\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;31m\\\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m  \u001B[0;34m.\u001B[0m\u001B[0msetOutputCol\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"sentence_embeddings\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/annotator.py\u001B[0m in \u001B[0;36mpretrained\u001B[0;34m(name, lang, remote_loc)\u001B[0m\n\u001B[1;32m   7531\u001B[0m         \"\"\"\n\u001B[1;32m   7532\u001B[0m         \u001B[0;32mfrom\u001B[0m \u001B[0msparknlp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpretrained\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mResourceDownloader\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 7533\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mResourceDownloader\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdownloadModel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mUniversalSentenceEncoder\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlang\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mremote_loc\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   7534\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   7535\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/pretrained.py\u001B[0m in \u001B[0;36mdownloadModel\u001B[0;34m(reader, name, language, remote_loc, j_dwn)\u001B[0m\n\u001B[1;32m     57\u001B[0m             \u001B[0mt1\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstart\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     58\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 59\u001B[0;31m                 \u001B[0mj_obj\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_internal\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_DownloadModel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mreader\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlanguage\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mremote_loc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mj_dwn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     60\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0mPy4JJavaError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     61\u001B[0m                 \u001B[0msys\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstdout\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwrite\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"\\n\"\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/internal.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, reader, name, language, remote_loc, validator)\u001B[0m\n\u001B[1;32m    211\u001B[0m \u001B[0;32mclass\u001B[0m \u001B[0m_DownloadModel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mExtendedJavaWrapper\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    212\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__init__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreader\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlanguage\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mremote_loc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalidator\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 213\u001B[0;31m         super(_DownloadModel, self).__init__(\"com.johnsnowlabs.nlp.pretrained.\" + validator + \".downloadModel\", reader,\n\u001B[0m\u001B[1;32m    214\u001B[0m                                              name, language, remote_loc)\n\u001B[1;32m    215\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/internal.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, java_obj, *args)\u001B[0m\n\u001B[1;32m    163\u001B[0m         \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mExtendedJavaWrapper\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__init__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mjava_obj\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    164\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msc\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mSparkContext\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_active_spark_context\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 165\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_java_obj\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnew_java_obj\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mjava_obj\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    166\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjava_obj\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_java_obj\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    167\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m/opt/conda/miniconda3/lib/python3.8/site-packages/sparknlp/internal.py\u001B[0m in \u001B[0;36mnew_java_obj\u001B[0;34m(self, java_class, *args)\u001B[0m\n\u001B[1;32m    173\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    174\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mnew_java_obj\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mjava_class\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 175\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_new_java_obj\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mjava_class\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    176\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    177\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mnew_java_array\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpylist\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mjava_class\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m/usr/lib/spark/python/pyspark/ml/wrapper.py\u001B[0m in \u001B[0;36m_new_java_obj\u001B[0;34m(java_class, *args)\u001B[0m\n\u001B[1;32m     64\u001B[0m             \u001B[0mjava_obj\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mjava_obj\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     65\u001B[0m         \u001B[0mjava_args\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0m_py2java\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0marg\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0marg\u001B[0m \u001B[0;32min\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 66\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mjava_obj\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0mjava_args\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     67\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     68\u001B[0m     \u001B[0;34m@\u001B[0m\u001B[0mstaticmethod\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1301\u001B[0m             \u001B[0mproto\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mEND_COMMAND_PART\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1302\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1303\u001B[0;31m         \u001B[0manswer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgateway_client\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msend_command\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcommand\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1304\u001B[0m         return_value = get_return_value(\n\u001B[1;32m   1305\u001B[0m             answer, self.gateway_client, self.target_id, self.name)\n","\u001B[0;32m/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001B[0m in \u001B[0;36msend_command\u001B[0;34m(self, command, retry, binary)\u001B[0m\n\u001B[1;32m   1031\u001B[0m         \u001B[0mconnection\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_get_connection\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1032\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1033\u001B[0;31m             \u001B[0mresponse\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mconnection\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msend_command\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcommand\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1034\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mbinary\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1035\u001B[0m                 \u001B[0;32mreturn\u001B[0m \u001B[0mresponse\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_create_connection_guard\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mconnection\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001B[0m in \u001B[0;36msend_command\u001B[0;34m(self, command)\u001B[0m\n\u001B[1;32m   1198\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1199\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1200\u001B[0;31m             \u001B[0manswer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msmart_decode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstream\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreadline\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1201\u001B[0m             \u001B[0mlogger\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdebug\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Answer received: {0}\"\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0manswer\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1202\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0manswer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstartswith\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mproto\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mRETURN_MESSAGE\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m/opt/conda/miniconda3/lib/python3.8/socket.py\u001B[0m in \u001B[0;36mreadinto\u001B[0;34m(self, b)\u001B[0m\n\u001B[1;32m    667\u001B[0m         \u001B[0;32mwhile\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    668\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 669\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_sock\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrecv_into\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mb\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    670\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0mtimeout\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    671\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_timeout_occurred\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;31mKeyboardInterrupt\u001B[0m: "]}],"source":["documentAssembler = DocumentAssembler()\\\n","    .setInputCol(\"text\")\\\n","    .setOutputCol(\"document\")\n","    \n","use = UniversalSentenceEncoder.pretrained(name=\"tfhub_use\", lang=\"en\")\\\n"," .setInputCols([\"document\"])\\\n"," .setOutputCol(\"sentence_embeddings\")\n","\n","\n","sentimentdl = ClassifierDLModel.pretrained(name=model_name)\\\n","    .setInputCols([\"sentence_embeddings\"])\\\n","    .setOutputCol(\"sentiment\")\n","\n","nlpPipeline = Pipeline(\n","      stages = [\n","          documentAssembler,\n","          use,\n","          sentimentdl\n","      ])"]},{"cell_type":"code","execution_count":15,"id":"9dab9bea","metadata":{},"outputs":[],"source":["empty_df = spark.createDataFrame([['']]).toDF(\"text\")\n","pipelineModel = nlpPipeline.fit(empty_df)\n","df = df2.withColumn('text', col('tweet2'))\n","result = pipelineModel.transform(df)"]},{"cell_type":"code","execution_count":43,"id":"0b16cb88","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["21/12/01 16:47:55 WARN org.apache.spark.deploy.yarn.YarnAllocator: Container from a bad node: container_1638368004038_0006_01_000010 on host: bigdatacluster2-w-3.us-west1-a.c.even-hull-328204.internal. Exit status: 143. Diagnostics: [2021-12-01 16:47:55.634]Container killed on request. Exit code is 143\n","[2021-12-01 16:47:55.634]Container exited with a non-zero exit code 143. \n","[2021-12-01 16:47:55.634]Killed by external signal\n",".\n","21/12/01 16:47:55 WARN org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 10 for reason Container from a bad node: container_1638368004038_0006_01_000010 on host: bigdatacluster2-w-3.us-west1-a.c.even-hull-328204.internal. Exit status: 143. Diagnostics: [2021-12-01 16:47:55.634]Container killed on request. Exit code is 143\n","[2021-12-01 16:47:55.634]Container exited with a non-zero exit code 143. \n","[2021-12-01 16:47:55.634]Killed by external signal\n",".\n","21/12/01 16:47:55 ERROR org.apache.spark.scheduler.cluster.YarnScheduler: Lost executor 10 on bigdatacluster2-w-3.us-west1-a.c.even-hull-328204.internal: Container from a bad node: container_1638368004038_0006_01_000010 on host: bigdatacluster2-w-3.us-west1-a.c.even-hull-328204.internal. Exit status: 143. Diagnostics: [2021-12-01 16:47:55.634]Container killed on request. Exit code is 143\n","[2021-12-01 16:47:55.634]Container exited with a non-zero exit code 143. \n","[2021-12-01 16:47:55.634]Killed by external signal\n",".\n","21/12/01 16:47:55 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 0.0 in stage 16.0 (TID 22) (bigdatacluster2-w-3.us-west1-a.c.even-hull-328204.internal executor 10): ExecutorLostFailure (executor 10 exited caused by one of the running tasks) Reason: Container from a bad node: container_1638368004038_0006_01_000010 on host: bigdatacluster2-w-3.us-west1-a.c.even-hull-328204.internal. Exit status: 143. Diagnostics: [2021-12-01 16:47:55.634]Container killed on request. Exit code is 143\n","[2021-12-01 16:47:55.634]Container exited with a non-zero exit code 143. \n","[2021-12-01 16:47:55.634]Killed by external signal\n",".\n","[Stage 16:>                                                         (0 + 1) / 1]\r"]},{"name":"stdout","output_type":"stream","text":["+-------------------+----------+--------+-----+--------------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n","|           tweet_id|     tdate|   ttime|tlang|tcountry_place|month_year|               tweet|              tweet1|              tweet2|                text|            document| sentence_embeddings|           sentiment|\n","+-------------------+----------+--------+-----+--------------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n","|1387861806589358087|2021-04-29|20:10:14|   en|          NULL|   2021-04|Thank God...letâ€™s...|Thank God...letâ€™s...|Thank God...letâ€™s...|Thank God...letâ€™s...|[{document, 0, 90...|[{sentence_embedd...|[{category, 0, 90...|\n","|1387861807532896258|2021-04-29|20:10:14|   en|          NULL|   2021-04|ðŸ‘‡ðŸ’¥ðŸ‘‡ðŸ’¥ðŸ‘‡OHH FFS...|ðŸ‘‡ðŸ’¥ðŸ‘‡ðŸ’¥ðŸ‘‡OHH FFS...|  ðŸ‘‡ðŸ’¥ðŸ‘‡ðŸ’¥ðŸ‘‡OHH FFS |  ðŸ‘‡ðŸ’¥ðŸ‘‡ðŸ’¥ðŸ‘‡OHH FFS |[{document, 0, 17...|[{sentence_embedd...|[{category, 0, 17...|\n","|1387861812369100800|2021-04-29|20:10:15|   en|          NULL|   2021-04|Significant news\n","...|Significant news\n","...|Significant news\n","...|Significant news\n","...|[{document, 0, 19...|[{sentence_embedd...|[{category, 0, 19...|\n","|1387861814399029251|2021-04-29|20:10:16|   en|          NULL|   2021-04|@fox12oregon Peop...|fox12oregon Peopl...|fox12oregon Peopl...|fox12oregon Peopl...|[{document, 0, 14...|[{sentence_embedd...|[{category, 0, 14...|\n","|1387861820866809857|2021-04-29|20:10:17|   en|          NULL|   2021-04|Help out if you c...|Help out if you c...|Help out if you c...|Help out if you c...|[{document, 0, 22...|[{sentence_embedd...|[{category, 0, 22...|\n","|1387861827992932356|2021-04-29|20:10:19|   en|          NULL|   2021-04|BioNTech to reque...|BioNTech to reque...|BioNTech to reque...|BioNTech to reque...|[{document, 0, 74...|[{sentence_embedd...|[{category, 0, 74...|\n","|1387861829016334345|2021-04-29|20:10:19|   en|          NULL|   2021-04|#FordMustResign  ...|#FordMustResign  ...|FordMustResign  E...|FordMustResign  E...|[{document, 0, 22...|[{sentence_embedd...|[{category, 0, 22...|\n","|1387861832124227587|2021-04-29|20:10:20|   en|          NULL|   2021-04|58. A thread comp...|58. A thread comp...|58. A thread comp...|58. A thread comp...|[{document, 0, 22...|[{sentence_embedd...|[{category, 0, 22...|\n","|1387861836717084677|2021-04-29|20:10:21|   en|          NULL|   2021-04|Good. Itâ€™s deserv...|Good. Itâ€™s deserv...|Good. Itâ€™s deserv...|Good. Itâ€™s deserv...|[{document, 0, 23...|[{sentence_embedd...|[{category, 0, 23...|\n","|1387861845336338434|2021-04-29|20:10:23|   en|          NULL|   2021-04|With a million pf...|With a million pf...|With a million pf...|With a million pf...|[{document, 0, 22...|[{sentence_embedd...|[{category, 0, 22...|\n","|1387861845667684354|2021-04-29|20:10:23|   en|          NULL|   2021-04|@propaganda_joe @...|propaganda_joe ca...|propaganda_joe ca...|propaganda_joe ca...|[{document, 0, 26...|[{sentence_embedd...|[{category, 0, 26...|\n","|1387861853678804996|2021-04-29|20:10:25|   en|          NULL|   2021-04|Michiganders comp...|Michiganders comp...|Michiganders comp...|Michiganders comp...|[{document, 0, 11...|[{sentence_embedd...|[{category, 0, 11...|\n","|1387861855096344577|2021-04-29|20:10:26|   en|          NULL|   2021-04|#SOS Agra #Covid\n","...|#SOS Agra #Covid\n","...|SOS Agra Covid\n","Ur...|SOS Agra Covid\n","Ur...|[{document, 0, 26...|[{sentence_embedd...|[{category, 0, 26...|\n","|1387861855486554114|2021-04-29|20:10:26|   en|          NULL|   2021-04|Just a reminder h...|Just a reminder h...|Just a reminder h...|Just a reminder h...|[{document, 0, 43...|[{sentence_embedd...|[{category, 0, 43...|\n","|1387861863698878464|2021-04-29|20:10:28|   en|          NULL|   2021-04|ðŸ¦  ðŸš¨ UPDATE: Ano...|ðŸ¦  ðŸš¨ UPDATE: Ano...|ðŸ¦  ðŸš¨ UPDATE Anot...|ðŸ¦  ðŸš¨ UPDATE Anot...|[{document, 0, 22...|[{sentence_embedd...|[{category, 0, 22...|\n","|1387861864688734208|2021-04-29|20:10:28|   en|          NULL|   2021-04|Ya we do!!! https...|Ya we do!!! https...|        Ya we do!!! |        Ya we do!!! |[{document, 0, 11...|[{sentence_embedd...|[{category, 0, 11...|\n","|1387861866635046914|2021-04-29|20:10:28|   en|          NULL|   2021-04|COVID hospitaliza...|COVID hospitaliza...|COVID hospitaliza...|COVID hospitaliza...|[{document, 0, 73...|[{sentence_embedd...|[{category, 0, 73...|\n","|1387861869784977409|2021-04-29|20:10:29|   en|          NULL|   2021-04|Does this surpris...|Does this surpris...|Does this surpris...|Does this surpris...|[{document, 0, 23...|[{sentence_embedd...|[{category, 0, 23...|\n","|1387861871743668228|2021-04-29|20:10:30|   en|          NULL|   2021-04|However, medical ...|However, medical ...|However, medical ...|However, medical ...|[{document, 0, 22...|[{sentence_embedd...|[{category, 0, 22...|\n","|1387861875552047104|2021-04-29|20:10:31|   en|          NULL|   2021-04|One year ago, we ...|One year ago, we ...|One year ago, we ...|One year ago, we ...|[{document, 0, 25...|[{sentence_embedd...|[{category, 0, 25...|\n","+-------------------+----------+--------+-----+--------------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n","only showing top 20 rows\n","\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["result.show()"]},{"cell_type":"code","execution_count":20,"id":"a323e730","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+----------+\n","|    result|\n","+----------+\n","|    [fear]|\n","|    [fear]|\n","|    [fear]|\n","|    [fear]|\n","|     [joy]|\n","|     [joy]|\n","|    [fear]|\n","|    [fear]|\n","|[surprise]|\n","|    [fear]|\n","|    [fear]|\n","| [sadness]|\n","|[surprise]|\n","|[surprise]|\n","|    [fear]|\n","|    [fear]|\n","|    [fear]|\n","|    [fear]|\n","|    [fear]|\n","|     [joy]|\n","+----------+\n","only showing top 20 rows\n","\n"]}],"source":["result.select('sentiment.result').show()"]},{"cell_type":"code","execution_count":16,"id":"d5a19f1a","metadata":{},"outputs":[],"source":["df_res = result.selectExpr(\"tweet_id\",\"text\",\"tdate\",\"tcountry_place\",\"month_year\",\"explode(sentiment.metadata) sentiments\", \"sentiment\") \\\n","        .selectExpr(\"tweet_id\",\"text\",\"tdate\",\"tcountry_place\",\"month_year\",\"explode(sentiments)\", \"sentiment.result result\")\n","\n"]},{"cell_type":"code","execution_count":40,"id":"e519f2d8","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["21/12/01 15:51:57 WARN org.apache.spark.deploy.yarn.YarnAllocator: Container from a bad node: container_1638368004038_0005_01_000005 on host: bigdatacluster2-w-2.us-west1-a.c.even-hull-328204.internal. Exit status: 143. Diagnostics: [2021-12-01 15:51:57.394]Container killed on request. Exit code is 143\n","[2021-12-01 15:51:57.395]Container exited with a non-zero exit code 143. \n","[2021-12-01 15:51:57.395]Killed by external signal\n",".\n","21/12/01 15:51:57 WARN org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 5 for reason Container from a bad node: container_1638368004038_0005_01_000005 on host: bigdatacluster2-w-2.us-west1-a.c.even-hull-328204.internal. Exit status: 143. Diagnostics: [2021-12-01 15:51:57.394]Container killed on request. Exit code is 143\n","[2021-12-01 15:51:57.395]Container exited with a non-zero exit code 143. \n","[2021-12-01 15:51:57.395]Killed by external signal\n",".\n","21/12/01 15:51:57 ERROR org.apache.spark.scheduler.cluster.YarnScheduler: Lost executor 5 on bigdatacluster2-w-2.us-west1-a.c.even-hull-328204.internal: Container from a bad node: container_1638368004038_0005_01_000005 on host: bigdatacluster2-w-2.us-west1-a.c.even-hull-328204.internal. Exit status: 143. Diagnostics: [2021-12-01 15:51:57.394]Container killed on request. Exit code is 143\n","[2021-12-01 15:51:57.395]Container exited with a non-zero exit code 143. \n","[2021-12-01 15:51:57.395]Killed by external signal\n",".\n","21/12/01 15:51:57 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 0.0 in stage 21.0 (TID 23) (bigdatacluster2-w-2.us-west1-a.c.even-hull-328204.internal executor 5): ExecutorLostFailure (executor 5 exited caused by one of the running tasks) Reason: Container from a bad node: container_1638368004038_0005_01_000005 on host: bigdatacluster2-w-2.us-west1-a.c.even-hull-328204.internal. Exit status: 143. Diagnostics: [2021-12-01 15:51:57.394]Container killed on request. Exit code is 143\n","[2021-12-01 15:51:57.395]Container exited with a non-zero exit code 143. \n","[2021-12-01 15:51:57.395]Killed by external signal\n",".\n","21/12/01 15:52:17 WARN org.apache.spark.deploy.yarn.YarnAllocator: Container from a bad node: container_1638368004038_0005_01_000006 on host: bigdatacluster2-w-3.us-west1-a.c.even-hull-328204.internal. Exit status: 143. Diagnostics: [2021-12-01 15:52:17.789]Container killed on request. Exit code is 143\n","[2021-12-01 15:52:17.790]Container exited with a non-zero exit code 143. \n","[2021-12-01 15:52:17.790]Killed by external signal\n",".\n","21/12/01 15:52:17 WARN org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 6 for reason Container from a bad node: container_1638368004038_0005_01_000006 on host: bigdatacluster2-w-3.us-west1-a.c.even-hull-328204.internal. Exit status: 143. Diagnostics: [2021-12-01 15:52:17.789]Container killed on request. Exit code is 143\n","[2021-12-01 15:52:17.790]Container exited with a non-zero exit code 143. \n","[2021-12-01 15:52:17.790]Killed by external signal\n",".\n","21/12/01 15:52:17 ERROR org.apache.spark.scheduler.cluster.YarnScheduler: Lost executor 6 on bigdatacluster2-w-3.us-west1-a.c.even-hull-328204.internal: Container from a bad node: container_1638368004038_0005_01_000006 on host: bigdatacluster2-w-3.us-west1-a.c.even-hull-328204.internal. Exit status: 143. Diagnostics: [2021-12-01 15:52:17.789]Container killed on request. Exit code is 143\n","[2021-12-01 15:52:17.790]Container exited with a non-zero exit code 143. \n","[2021-12-01 15:52:17.790]Killed by external signal\n",".\n","21/12/01 15:52:17 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 0.1 in stage 21.0 (TID 24) (bigdatacluster2-w-3.us-west1-a.c.even-hull-328204.internal executor 6): ExecutorLostFailure (executor 6 exited caused by one of the running tasks) Reason: Container from a bad node: container_1638368004038_0005_01_000006 on host: bigdatacluster2-w-3.us-west1-a.c.even-hull-328204.internal. Exit status: 143. Diagnostics: [2021-12-01 15:52:17.789]Container killed on request. Exit code is 143\n","[2021-12-01 15:52:17.790]Container exited with a non-zero exit code 143. \n","[2021-12-01 15:52:17.790]Killed by external signal\n",".\n","21/12/01 15:52:37 WARN org.apache.spark.deploy.yarn.YarnAllocator: Container from a bad node: container_1638368004038_0005_01_000007 on host: bigdatacluster2-w-0.us-west1-a.c.even-hull-328204.internal. Exit status: 143. Diagnostics: [2021-12-01 15:52:38.100]Container killed on request. Exit code is 143\n","[2021-12-01 15:52:38.100]Container exited with a non-zero exit code 143. \n","[2021-12-01 15:52:38.101]Killed by external signal\n",".\n","21/12/01 15:52:37 WARN org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 7 for reason Container from a bad node: container_1638368004038_0005_01_000007 on host: bigdatacluster2-w-0.us-west1-a.c.even-hull-328204.internal. Exit status: 143. Diagnostics: [2021-12-01 15:52:38.100]Container killed on request. Exit code is 143\n","[2021-12-01 15:52:38.100]Container exited with a non-zero exit code 143. \n","[2021-12-01 15:52:38.101]Killed by external signal\n",".\n","21/12/01 15:52:37 ERROR org.apache.spark.scheduler.cluster.YarnScheduler: Lost executor 7 on bigdatacluster2-w-0.us-west1-a.c.even-hull-328204.internal: Container from a bad node: container_1638368004038_0005_01_000007 on host: bigdatacluster2-w-0.us-west1-a.c.even-hull-328204.internal. Exit status: 143. Diagnostics: [2021-12-01 15:52:38.100]Container killed on request. Exit code is 143\n","[2021-12-01 15:52:38.100]Container exited with a non-zero exit code 143. \n","[2021-12-01 15:52:38.101]Killed by external signal\n",".\n","21/12/01 15:52:37 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 0.2 in stage 21.0 (TID 25) (bigdatacluster2-w-0.us-west1-a.c.even-hull-328204.internal executor 7): ExecutorLostFailure (executor 7 exited caused by one of the running tasks) Reason: Container from a bad node: container_1638368004038_0005_01_000007 on host: bigdatacluster2-w-0.us-west1-a.c.even-hull-328204.internal. Exit status: 143. Diagnostics: [2021-12-01 15:52:38.100]Container killed on request. Exit code is 143\n","[2021-12-01 15:52:38.100]Container exited with a non-zero exit code 143. \n","[2021-12-01 15:52:38.101]Killed by external signal\n",".\n","21/12/01 15:52:57 WARN org.apache.spark.deploy.yarn.YarnAllocator: Container from a bad node: container_1638368004038_0005_01_000008 on host: bigdatacluster2-w-2.us-west1-a.c.even-hull-328204.internal. Exit status: 143. Diagnostics: [2021-12-01 15:52:58.007]Container killed on request. Exit code is 143\n","[2021-12-01 15:52:58.007]Container exited with a non-zero exit code 143. \n","[2021-12-01 15:52:58.008]Killed by external signal\n",".\n","21/12/01 15:52:57 WARN org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 8 for reason Container from a bad node: container_1638368004038_0005_01_000008 on host: bigdatacluster2-w-2.us-west1-a.c.even-hull-328204.internal. Exit status: 143. Diagnostics: [2021-12-01 15:52:58.007]Container killed on request. Exit code is 143\n","[2021-12-01 15:52:58.007]Container exited with a non-zero exit code 143. \n","[2021-12-01 15:52:58.008]Killed by external signal\n",".\n","21/12/01 15:52:57 ERROR org.apache.spark.scheduler.cluster.YarnScheduler: Lost executor 8 on bigdatacluster2-w-2.us-west1-a.c.even-hull-328204.internal: Container from a bad node: container_1638368004038_0005_01_000008 on host: bigdatacluster2-w-2.us-west1-a.c.even-hull-328204.internal. Exit status: 143. Diagnostics: [2021-12-01 15:52:58.007]Container killed on request. Exit code is 143\n","[2021-12-01 15:52:58.007]Container exited with a non-zero exit code 143. \n","[2021-12-01 15:52:58.008]Killed by external signal\n",".\n","21/12/01 15:52:57 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 0.3 in stage 21.0 (TID 26) (bigdatacluster2-w-2.us-west1-a.c.even-hull-328204.internal executor 8): ExecutorLostFailure (executor 8 exited caused by one of the running tasks) Reason: Container from a bad node: container_1638368004038_0005_01_000008 on host: bigdatacluster2-w-2.us-west1-a.c.even-hull-328204.internal. Exit status: 143. Diagnostics: [2021-12-01 15:52:58.007]Container killed on request. Exit code is 143\n","[2021-12-01 15:52:58.007]Container exited with a non-zero exit code 143. \n","[2021-12-01 15:52:58.008]Killed by external signal\n",".\n","21/12/01 15:52:57 ERROR org.apache.spark.scheduler.TaskSetManager: Task 0 in stage 21.0 failed 4 times; aborting job\n"]},{"ename":"Py4JJavaError","evalue":"An error occurred while calling o860.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 21.0 failed 4 times, most recent failure: Lost task 0.3 in stage 21.0 (TID 26) (bigdatacluster2-w-2.us-west1-a.c.even-hull-328204.internal executor 8): ExecutorLostFailure (executor 8 exited caused by one of the running tasks) Reason: Container from a bad node: container_1638368004038_0005_01_000008 on host: bigdatacluster2-w-2.us-west1-a.c.even-hull-328204.internal. Exit status: 143. Diagnostics: [2021-12-01 15:52:58.007]Container killed on request. Exit code is 143\n[2021-12-01 15:52:58.007]Container exited with a non-zero exit code 143. \n[2021-12-01 15:52:58.008]Killed by external signal\n.\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2259)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2208)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2207)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2207)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1079)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1079)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1079)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2446)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2388)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2377)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2204)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2225)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2244)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:472)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:425)\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:47)\n\tat org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:3696)\n\tat org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:2722)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2722)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2929)\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:301)\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:338)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n","output_type":"error","traceback":["\u001B[0;31m---------------------------------------------------------------------------\u001B[0m","\u001B[0;31mPy4JJavaError\u001B[0m                             Traceback (most recent call last)","\u001B[0;32m/tmp/ipykernel_12198/2303750471.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mdf_res\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshow\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m","\u001B[0;32m/usr/lib/spark/python/pyspark/sql/dataframe.py\u001B[0m in \u001B[0;36mshow\u001B[0;34m(self, n, truncate, vertical)\u001B[0m\n\u001B[1;32m    482\u001B[0m         \"\"\"\n\u001B[1;32m    483\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtruncate\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbool\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mtruncate\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 484\u001B[0;31m             \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jdf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshowString\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mn\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m20\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvertical\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    485\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    486\u001B[0m             \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jdf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshowString\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mn\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtruncate\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvertical\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1302\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1303\u001B[0m         \u001B[0manswer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgateway_client\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msend_command\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcommand\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1304\u001B[0;31m         return_value = get_return_value(\n\u001B[0m\u001B[1;32m   1305\u001B[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001B[1;32m   1306\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m/usr/lib/spark/python/pyspark/sql/utils.py\u001B[0m in \u001B[0;36mdeco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    109\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mdeco\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkw\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    110\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 111\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkw\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    112\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mpy4j\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprotocol\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mPy4JJavaError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    113\u001B[0m             \u001B[0mconverted\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mconvert_exception\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjava_exception\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py\u001B[0m in \u001B[0;36mget_return_value\u001B[0;34m(answer, gateway_client, target_id, name)\u001B[0m\n\u001B[1;32m    324\u001B[0m             \u001B[0mvalue\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mOUTPUT_CONVERTER\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mtype\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0manswer\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgateway_client\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    325\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0manswer\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0mREFERENCE_TYPE\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 326\u001B[0;31m                 raise Py4JJavaError(\n\u001B[0m\u001B[1;32m    327\u001B[0m                     \u001B[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    328\u001B[0m                     format(target_id, \".\", name), value)\n","\u001B[0;31mPy4JJavaError\u001B[0m: An error occurred while calling o860.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 21.0 failed 4 times, most recent failure: Lost task 0.3 in stage 21.0 (TID 26) (bigdatacluster2-w-2.us-west1-a.c.even-hull-328204.internal executor 8): ExecutorLostFailure (executor 8 exited caused by one of the running tasks) Reason: Container from a bad node: container_1638368004038_0005_01_000008 on host: bigdatacluster2-w-2.us-west1-a.c.even-hull-328204.internal. Exit status: 143. Diagnostics: [2021-12-01 15:52:58.007]Container killed on request. Exit code is 143\n[2021-12-01 15:52:58.007]Container exited with a non-zero exit code 143. \n[2021-12-01 15:52:58.008]Killed by external signal\n.\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2259)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2208)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2207)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2207)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1079)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1079)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1079)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2446)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2388)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2377)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2204)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2225)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2244)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:472)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:425)\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:47)\n\tat org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:3696)\n\tat org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:2722)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2722)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2929)\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:301)\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:338)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n"]}],"source":["df_res.show()"]},{"cell_type":"code","execution_count":17,"id":"fdbe6211","metadata":{},"outputs":[],"source":["df_res = df_res.drop('key', 'value')"]},{"cell_type":"code","execution_count":1,"id":"56a8e1e4","metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'df_res' is not defined","output_type":"error","traceback":["\u001B[0;31m---------------------------------------------------------------------------\u001B[0m","\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)","\u001B[0;32m/tmp/ipykernel_4108/4166029137.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mdf_res\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdf_res\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdistinct\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m","\u001B[0;31mNameError\u001B[0m: name 'df_res' is not defined"]}],"source":["df_res = df_res.distinct()"]},{"cell_type":"code","execution_count":19,"id":"d41f2c5f","metadata":{},"outputs":[],"source":["df_res_2 = df_res.withColumnRenamed(\"value\", \"emotion_score\")"]},{"cell_type":"code","execution_count":20,"id":"d6a20238","metadata":{},"outputs":[],"source":["df_res_2 = df_res_2.withColumnRenamed(\"result\", \"emotion\")"]},{"cell_type":"code","execution_count":28,"id":"ebd4c060","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 15:>                                                         (0 + 1) / 1]\r"]},{"name":"stdout","output_type":"stream","text":["+-------------------+--------------------+----------+--------------+----------+---------+\n","|           tweet_id|                text|     tdate|tcountry_place|month_year|  emotion|\n","+-------------------+--------------------+----------+--------------+----------+---------+\n","|1387861939292880900|Tarrant County Sp...|2021-04-29|          NULL|   2021-04|    [joy]|\n","|1388023549659471875|We need to end le...|2021-04-30|          NULL|   2021-04|   [fear]|\n","|1388024510184497153|Sp00nerism Game O...|2021-04-30|          NULL|   2021-04|    [joy]|\n","|1388115803803848707|Who have province...|2021-04-30|          NULL|   2021-04|    [joy]|\n","|1388137041846628356|IrfanAnsariMLA Da...|2021-04-30|          NULL|   2021-04|   [fear]|\n","|1388155784144424961|GovSisolak The CO...|2021-04-30|          NULL|   2021-04|   [fear]|\n","|1388162498671435776|Thai government p...|2021-04-30|          NULL|   2021-04|   [fear]|\n","|1388170136130134029|Hey Michiganders ...|2021-04-30|          NULL|   2021-04|   [fear]|\n","|1388191053962891265|\"We need more Car...|2021-04-30|            IN|   2021-04|   [fear]|\n","|1388191502015336450|46.8% of NewYork'...|2021-04-30|          NULL|   2021-04|   [fear]|\n","|1388233862971592716|After a year plus...|2021-04-30|          NULL|   2021-04|[sadness]|\n","|1388247404122677251|The_BMC Need urge...|2021-04-30|          NULL|   2021-04|    [joy]|\n","|1388256127717105667|Good news\n","\n","COVID1...|2021-04-30|          NULL|   2021-04|    [joy]|\n","|1387961994372780034|Covid-19 Air NZ r...|2021-04-30|          NULL|   2021-04|   [fear]|\n","|1387962123846766592|Latest Covid19 in...|2021-04-30|          NULL|   2021-04|    [joy]|\n","|1388050251920003072|Shocking! Can't b...|2021-04-30|          NULL|   2021-04|[sadness]|\n","|1388056807571025924|IwillDonatePlasma...|2021-04-30|          NULL|   2021-04|    [joy]|\n","|1388155795087544325|Historicmoment in...|2021-04-30|          NULL|   2021-04|   [fear]|\n","|1388170144308936704|Some heartfelt wo...|2021-04-30|          NULL|   2021-04|    [joy]|\n","|1388191068940902402|I having issues i...|2021-04-30|          NULL|   2021-04|[sadness]|\n","+-------------------+--------------------+----------+--------------+----------+---------+\n","only showing top 20 rows\n","\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["df_res_2.show()"]},{"cell_type":"code","execution_count":21,"id":"8e60aeb7","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- tweet_id: long (nullable = true)\n"," |-- text: string (nullable = true)\n"," |-- tdate: string (nullable = true)\n"," |-- tcountry_place: string (nullable = true)\n"," |-- month_year: string (nullable = true)\n"," |-- emotion: string (nullable = false)\n","\n"]}],"source":["from pyspark.sql.functions import col, concat_ws\n","df_res_2 = df_res_2.withColumn(\"emotion\",\n","   concat_ws(\",\",col(\"emotion\")))\n","df_res_2.printSchema()"]},{"cell_type":"code","execution_count":22,"id":"88603812","metadata":{},"outputs":[],"source":["df_result_joy = df_res_2.filter(df_res_2.emotion == \"joy\")\n","df_result_fear = df_res_2.filter(df_res_2.emotion == \"fear\")\n","df_result_surprise = df_res_2.filter(df_res_2.emotion == \"sadness\")\n","df_result_sadness = df_res_2.filter(df_res_2.emotion == \"surprise\")"]},{"cell_type":"code","execution_count":70,"id":"fca3eff2","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["21/12/01 17:16:43 WARN org.apache.spark.deploy.yarn.YarnAllocator: Container from a bad node: container_1638368004038_0006_01_000021 on host: bigdatacluster2-w-2.us-west1-a.c.even-hull-328204.internal. Exit status: 143. Diagnostics: [2021-12-01 17:16:44.285]Container killed on request. Exit code is 143\n","[2021-12-01 17:16:44.285]Container exited with a non-zero exit code 143. \n","[2021-12-01 17:16:44.285]Killed by external signal\n",".\n","21/12/01 17:16:43 WARN org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 21 for reason Container from a bad node: container_1638368004038_0006_01_000021 on host: bigdatacluster2-w-2.us-west1-a.c.even-hull-328204.internal. Exit status: 143. Diagnostics: [2021-12-01 17:16:44.285]Container killed on request. Exit code is 143\n","[2021-12-01 17:16:44.285]Container exited with a non-zero exit code 143. \n","[2021-12-01 17:16:44.285]Killed by external signal\n",".\n","21/12/01 17:16:43 ERROR org.apache.spark.scheduler.cluster.YarnScheduler: Lost executor 21 on bigdatacluster2-w-2.us-west1-a.c.even-hull-328204.internal: Container from a bad node: container_1638368004038_0006_01_000021 on host: bigdatacluster2-w-2.us-west1-a.c.even-hull-328204.internal. Exit status: 143. Diagnostics: [2021-12-01 17:16:44.285]Container killed on request. Exit code is 143\n","[2021-12-01 17:16:44.285]Container exited with a non-zero exit code 143. \n","[2021-12-01 17:16:44.285]Killed by external signal\n",".\n","21/12/01 17:16:43 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 0.0 in stage 31.0 (TID 44) (bigdatacluster2-w-2.us-west1-a.c.even-hull-328204.internal executor 21): ExecutorLostFailure (executor 21 exited caused by one of the running tasks) Reason: Container from a bad node: container_1638368004038_0006_01_000021 on host: bigdatacluster2-w-2.us-west1-a.c.even-hull-328204.internal. Exit status: 143. Diagnostics: [2021-12-01 17:16:44.285]Container killed on request. Exit code is 143\n","[2021-12-01 17:16:44.285]Container exited with a non-zero exit code 143. \n","[2021-12-01 17:16:44.285]Killed by external signal\n",".\n","21/12/01 17:17:04 WARN org.apache.spark.deploy.yarn.YarnAllocator: Container from a bad node: container_1638368004038_0006_01_000022 on host: bigdatacluster2-w-3.us-west1-a.c.even-hull-328204.internal. Exit status: 143. Diagnostics: [2021-12-01 17:17:05.620]Container killed on request. Exit code is 143\n","[2021-12-01 17:17:05.621]Container exited with a non-zero exit code 143. \n","[2021-12-01 17:17:05.621]Killed by external signal\n",".\n","21/12/01 17:17:04 WARN org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 22 for reason Container from a bad node: container_1638368004038_0006_01_000022 on host: bigdatacluster2-w-3.us-west1-a.c.even-hull-328204.internal. Exit status: 143. Diagnostics: [2021-12-01 17:17:05.620]Container killed on request. Exit code is 143\n","[2021-12-01 17:17:05.621]Container exited with a non-zero exit code 143. \n","[2021-12-01 17:17:05.621]Killed by external signal\n",".\n","21/12/01 17:17:04 ERROR org.apache.spark.scheduler.cluster.YarnScheduler: Lost executor 22 on bigdatacluster2-w-3.us-west1-a.c.even-hull-328204.internal: Container from a bad node: container_1638368004038_0006_01_000022 on host: bigdatacluster2-w-3.us-west1-a.c.even-hull-328204.internal. Exit status: 143. Diagnostics: [2021-12-01 17:17:05.620]Container killed on request. Exit code is 143\n","[2021-12-01 17:17:05.621]Container exited with a non-zero exit code 143. \n","[2021-12-01 17:17:05.621]Killed by external signal\n",".\n","21/12/01 17:17:04 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 0.1 in stage 31.0 (TID 45) (bigdatacluster2-w-3.us-west1-a.c.even-hull-328204.internal executor 22): ExecutorLostFailure (executor 22 exited caused by one of the running tasks) Reason: Container from a bad node: container_1638368004038_0006_01_000022 on host: bigdatacluster2-w-3.us-west1-a.c.even-hull-328204.internal. Exit status: 143. Diagnostics: [2021-12-01 17:17:05.620]Container killed on request. Exit code is 143\n","[2021-12-01 17:17:05.621]Container exited with a non-zero exit code 143. \n","[2021-12-01 17:17:05.621]Killed by external signal\n",".\n","21/12/01 17:17:24 WARN org.apache.spark.deploy.yarn.YarnAllocator: Container from a bad node: container_1638368004038_0006_01_000023 on host: bigdatacluster2-w-0.us-west1-a.c.even-hull-328204.internal. Exit status: 143. Diagnostics: [2021-12-01 17:17:24.714]Container killed on request. Exit code is 143\n","[2021-12-01 17:17:24.714]Container exited with a non-zero exit code 143. \n","[2021-12-01 17:17:24.714]Killed by external signal\n",".\n","21/12/01 17:17:24 WARN org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 23 for reason Container from a bad node: container_1638368004038_0006_01_000023 on host: bigdatacluster2-w-0.us-west1-a.c.even-hull-328204.internal. Exit status: 143. Diagnostics: [2021-12-01 17:17:24.714]Container killed on request. Exit code is 143\n","[2021-12-01 17:17:24.714]Container exited with a non-zero exit code 143. \n","[2021-12-01 17:17:24.714]Killed by external signal\n",".\n","21/12/01 17:17:24 ERROR org.apache.spark.scheduler.cluster.YarnScheduler: Lost executor 23 on bigdatacluster2-w-0.us-west1-a.c.even-hull-328204.internal: Container from a bad node: container_1638368004038_0006_01_000023 on host: bigdatacluster2-w-0.us-west1-a.c.even-hull-328204.internal. Exit status: 143. Diagnostics: [2021-12-01 17:17:24.714]Container killed on request. Exit code is 143\n","[2021-12-01 17:17:24.714]Container exited with a non-zero exit code 143. \n","[2021-12-01 17:17:24.714]Killed by external signal\n",".\n","21/12/01 17:17:24 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 0.2 in stage 31.0 (TID 46) (bigdatacluster2-w-0.us-west1-a.c.even-hull-328204.internal executor 23): ExecutorLostFailure (executor 23 exited caused by one of the running tasks) Reason: Container from a bad node: container_1638368004038_0006_01_000023 on host: bigdatacluster2-w-0.us-west1-a.c.even-hull-328204.internal. Exit status: 143. Diagnostics: [2021-12-01 17:17:24.714]Container killed on request. Exit code is 143\n","[2021-12-01 17:17:24.714]Container exited with a non-zero exit code 143. \n","[2021-12-01 17:17:24.714]Killed by external signal\n",".\n","21/12/01 17:17:42 WARN org.apache.spark.deploy.yarn.YarnAllocator: Container from a bad node: container_1638368004038_0006_01_000024 on host: bigdatacluster2-w-1.us-west1-a.c.even-hull-328204.internal. Exit status: 143. Diagnostics: [2021-12-01 17:17:42.724]Container killed on request. Exit code is 143\n","[2021-12-01 17:17:42.725]Container exited with a non-zero exit code 143. \n","[2021-12-01 17:17:42.725]Killed by external signal\n",".\n","21/12/01 17:17:42 WARN org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 24 for reason Container from a bad node: container_1638368004038_0006_01_000024 on host: bigdatacluster2-w-1.us-west1-a.c.even-hull-328204.internal. Exit status: 143. Diagnostics: [2021-12-01 17:17:42.724]Container killed on request. Exit code is 143\n","[2021-12-01 17:17:42.725]Container exited with a non-zero exit code 143. \n","[2021-12-01 17:17:42.725]Killed by external signal\n",".\n","21/12/01 17:17:42 ERROR org.apache.spark.scheduler.cluster.YarnScheduler: Lost executor 24 on bigdatacluster2-w-1.us-west1-a.c.even-hull-328204.internal: Container from a bad node: container_1638368004038_0006_01_000024 on host: bigdatacluster2-w-1.us-west1-a.c.even-hull-328204.internal. Exit status: 143. Diagnostics: [2021-12-01 17:17:42.724]Container killed on request. Exit code is 143\n","[2021-12-01 17:17:42.725]Container exited with a non-zero exit code 143. \n","[2021-12-01 17:17:42.725]Killed by external signal\n",".\n","21/12/01 17:17:42 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 0.3 in stage 31.0 (TID 47) (bigdatacluster2-w-1.us-west1-a.c.even-hull-328204.internal executor 24): ExecutorLostFailure (executor 24 exited caused by one of the running tasks) Reason: Container from a bad node: container_1638368004038_0006_01_000024 on host: bigdatacluster2-w-1.us-west1-a.c.even-hull-328204.internal. Exit status: 143. Diagnostics: [2021-12-01 17:17:42.724]Container killed on request. Exit code is 143\n","[2021-12-01 17:17:42.725]Container exited with a non-zero exit code 143. \n","[2021-12-01 17:17:42.725]Killed by external signal\n",".\n","21/12/01 17:17:42 ERROR org.apache.spark.scheduler.TaskSetManager: Task 0 in stage 31.0 failed 4 times; aborting job\n"]},{"ename":"Py4JJavaError","evalue":"An error occurred while calling o1246.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 31.0 failed 4 times, most recent failure: Lost task 0.3 in stage 31.0 (TID 47) (bigdatacluster2-w-1.us-west1-a.c.even-hull-328204.internal executor 24): ExecutorLostFailure (executor 24 exited caused by one of the running tasks) Reason: Container from a bad node: container_1638368004038_0006_01_000024 on host: bigdatacluster2-w-1.us-west1-a.c.even-hull-328204.internal. Exit status: 143. Diagnostics: [2021-12-01 17:17:42.724]Container killed on request. Exit code is 143\n[2021-12-01 17:17:42.725]Container exited with a non-zero exit code 143. \n[2021-12-01 17:17:42.725]Killed by external signal\n.\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2259)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2208)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2207)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2207)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1079)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1079)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1079)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2446)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2388)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2377)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n","output_type":"error","traceback":["\u001B[0;31m---------------------------------------------------------------------------\u001B[0m","\u001B[0;31mPy4JJavaError\u001B[0m                             Traceback (most recent call last)","\u001B[0;32m/tmp/ipykernel_15576/748969324.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mdf_result_joy\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshow\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m","\u001B[0;32m/usr/lib/spark/python/pyspark/sql/dataframe.py\u001B[0m in \u001B[0;36mshow\u001B[0;34m(self, n, truncate, vertical)\u001B[0m\n\u001B[1;32m    482\u001B[0m         \"\"\"\n\u001B[1;32m    483\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtruncate\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbool\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mtruncate\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 484\u001B[0;31m             \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jdf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshowString\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mn\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m20\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvertical\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    485\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    486\u001B[0m             \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jdf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshowString\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mn\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtruncate\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvertical\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1302\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1303\u001B[0m         \u001B[0manswer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgateway_client\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msend_command\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcommand\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1304\u001B[0;31m         return_value = get_return_value(\n\u001B[0m\u001B[1;32m   1305\u001B[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001B[1;32m   1306\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m/usr/lib/spark/python/pyspark/sql/utils.py\u001B[0m in \u001B[0;36mdeco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    109\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mdeco\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkw\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    110\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 111\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkw\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    112\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mpy4j\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprotocol\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mPy4JJavaError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    113\u001B[0m             \u001B[0mconverted\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mconvert_exception\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjava_exception\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py\u001B[0m in \u001B[0;36mget_return_value\u001B[0;34m(answer, gateway_client, target_id, name)\u001B[0m\n\u001B[1;32m    324\u001B[0m             \u001B[0mvalue\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mOUTPUT_CONVERTER\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mtype\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0manswer\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgateway_client\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    325\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0manswer\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0mREFERENCE_TYPE\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 326\u001B[0;31m                 raise Py4JJavaError(\n\u001B[0m\u001B[1;32m    327\u001B[0m                     \u001B[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    328\u001B[0m                     format(target_id, \".\", name), value)\n","\u001B[0;31mPy4JJavaError\u001B[0m: An error occurred while calling o1246.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 31.0 failed 4 times, most recent failure: Lost task 0.3 in stage 31.0 (TID 47) (bigdatacluster2-w-1.us-west1-a.c.even-hull-328204.internal executor 24): ExecutorLostFailure (executor 24 exited caused by one of the running tasks) Reason: Container from a bad node: container_1638368004038_0006_01_000024 on host: bigdatacluster2-w-1.us-west1-a.c.even-hull-328204.internal. Exit status: 143. Diagnostics: [2021-12-01 17:17:42.724]Container killed on request. Exit code is 143\n[2021-12-01 17:17:42.725]Container exited with a non-zero exit code 143. \n[2021-12-01 17:17:42.725]Killed by external signal\n.\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2259)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2208)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2207)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2207)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1079)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1079)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1079)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2446)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2388)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2377)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n"]}],"source":["df_result_joy.show()"]},{"cell_type":"code","execution_count":null,"id":"3ac11e68","metadata":{},"outputs":[],"source":["#pdf_joy = pd.read_csv"]},{"cell_type":"code","execution_count":23,"id":"fa06b577","metadata":{"scrolled":false},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["pdf_joy = df_result_joy.toPandas()"]},{"cell_type":"code","execution_count":47,"id":"abbc87ad","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["21/12/01 15:58:02 WARN org.apache.spark.deploy.yarn.YarnAllocator: Container from a bad node: container_1638368004038_0005_01_000009 on host: bigdatacluster2-w-1.us-west1-a.c.even-hull-328204.internal. Exit status: 143. Diagnostics: [2021-12-01 15:58:02.500]Container killed on request. Exit code is 143\n","[2021-12-01 15:58:02.500]Container exited with a non-zero exit code 143. \n","[2021-12-01 15:58:02.500]Killed by external signal\n",".\n","21/12/01 15:58:02 WARN org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 9 for reason Container from a bad node: container_1638368004038_0005_01_000009 on host: bigdatacluster2-w-1.us-west1-a.c.even-hull-328204.internal. Exit status: 143. Diagnostics: [2021-12-01 15:58:02.500]Container killed on request. Exit code is 143\n","[2021-12-01 15:58:02.500]Container exited with a non-zero exit code 143. \n","[2021-12-01 15:58:02.500]Killed by external signal\n",".\n","21/12/01 15:58:02 ERROR org.apache.spark.scheduler.cluster.YarnScheduler: Lost executor 9 on bigdatacluster2-w-1.us-west1-a.c.even-hull-328204.internal: Container from a bad node: container_1638368004038_0005_01_000009 on host: bigdatacluster2-w-1.us-west1-a.c.even-hull-328204.internal. Exit status: 143. Diagnostics: [2021-12-01 15:58:02.500]Container killed on request. Exit code is 143\n","[2021-12-01 15:58:02.500]Container exited with a non-zero exit code 143. \n","[2021-12-01 15:58:02.500]Killed by external signal\n",".\n","21/12/01 15:58:02 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 0.0 in stage 25.0 (TID 31) (bigdatacluster2-w-1.us-west1-a.c.even-hull-328204.internal executor 9): ExecutorLostFailure (executor 9 exited caused by one of the running tasks) Reason: Container from a bad node: container_1638368004038_0005_01_000009 on host: bigdatacluster2-w-1.us-west1-a.c.even-hull-328204.internal. Exit status: 143. Diagnostics: [2021-12-01 15:58:02.500]Container killed on request. Exit code is 143\n","[2021-12-01 15:58:02.500]Container exited with a non-zero exit code 143. \n","[2021-12-01 15:58:02.500]Killed by external signal\n",".\n","21/12/01 15:58:23 WARN org.apache.spark.deploy.yarn.YarnAllocator: Container from a bad node: container_1638368004038_0005_01_000010 on host: bigdatacluster2-w-3.us-west1-a.c.even-hull-328204.internal. Exit status: 143. Diagnostics: [2021-12-01 15:58:23.774]Container killed on request. Exit code is 143\n","[2021-12-01 15:58:23.774]Container exited with a non-zero exit code 143. \n","[2021-12-01 15:58:23.775]Killed by external signal\n",".\n","21/12/01 15:58:23 WARN org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 10 for reason Container from a bad node: container_1638368004038_0005_01_000010 on host: bigdatacluster2-w-3.us-west1-a.c.even-hull-328204.internal. Exit status: 143. Diagnostics: [2021-12-01 15:58:23.774]Container killed on request. Exit code is 143\n","[2021-12-01 15:58:23.774]Container exited with a non-zero exit code 143. \n","[2021-12-01 15:58:23.775]Killed by external signal\n",".\n","21/12/01 15:58:23 ERROR org.apache.spark.scheduler.cluster.YarnScheduler: Lost executor 10 on bigdatacluster2-w-3.us-west1-a.c.even-hull-328204.internal: Container from a bad node: container_1638368004038_0005_01_000010 on host: bigdatacluster2-w-3.us-west1-a.c.even-hull-328204.internal. Exit status: 143. Diagnostics: [2021-12-01 15:58:23.774]Container killed on request. Exit code is 143\n","[2021-12-01 15:58:23.774]Container exited with a non-zero exit code 143. \n","[2021-12-01 15:58:23.775]Killed by external signal\n",".\n","21/12/01 15:58:23 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 0.1 in stage 25.0 (TID 32) (bigdatacluster2-w-3.us-west1-a.c.even-hull-328204.internal executor 10): ExecutorLostFailure (executor 10 exited caused by one of the running tasks) Reason: Container from a bad node: container_1638368004038_0005_01_000010 on host: bigdatacluster2-w-3.us-west1-a.c.even-hull-328204.internal. Exit status: 143. Diagnostics: [2021-12-01 15:58:23.774]Container killed on request. Exit code is 143\n","[2021-12-01 15:58:23.774]Container exited with a non-zero exit code 143. \n","[2021-12-01 15:58:23.775]Killed by external signal\n",".\n","[Stage 25:>                                                         (0 + 0) / 1]\r"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001B[0;31m---------------------------------------------------------------------------\u001B[0m","\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)","\u001B[0;32m/tmp/ipykernel_12198/2462136145.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0mpdf_joy\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdf_result_joy\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtoPandas\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mpdf_fear\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdf_result_fear\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtoPandas\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0mpdf_surprise\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdf_result_surprise\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtoPandas\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0mpdf_sadness\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdf_result_sadness\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtoPandas\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m/usr/lib/spark/python/pyspark/sql/pandas/conversion.py\u001B[0m in \u001B[0;36mtoPandas\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    139\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    140\u001B[0m         \u001B[0;31m# Below is toPandas without Arrow optimization.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 141\u001B[0;31m         \u001B[0mpdf\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mDataFrame\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfrom_records\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcollect\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcolumns\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    142\u001B[0m         \u001B[0mcolumn_counter\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mCounter\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    143\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m/usr/lib/spark/python/pyspark/sql/dataframe.py\u001B[0m in \u001B[0;36mcollect\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    675\u001B[0m         \"\"\"\n\u001B[1;32m    676\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mSCCallSiteSync\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_sc\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mcss\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 677\u001B[0;31m             \u001B[0msock_info\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jdf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcollectToPython\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    678\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_load_from_socket\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msock_info\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mBatchedSerializer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mPickleSerializer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    679\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1301\u001B[0m             \u001B[0mproto\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mEND_COMMAND_PART\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1302\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1303\u001B[0;31m         \u001B[0manswer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgateway_client\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msend_command\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcommand\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1304\u001B[0m         return_value = get_return_value(\n\u001B[1;32m   1305\u001B[0m             answer, self.gateway_client, self.target_id, self.name)\n","\u001B[0;32m/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001B[0m in \u001B[0;36msend_command\u001B[0;34m(self, command, retry, binary)\u001B[0m\n\u001B[1;32m   1031\u001B[0m         \u001B[0mconnection\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_get_connection\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1032\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1033\u001B[0;31m             \u001B[0mresponse\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mconnection\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msend_command\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcommand\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1034\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mbinary\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1035\u001B[0m                 \u001B[0;32mreturn\u001B[0m \u001B[0mresponse\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_create_connection_guard\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mconnection\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001B[0m in \u001B[0;36msend_command\u001B[0;34m(self, command)\u001B[0m\n\u001B[1;32m   1198\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1199\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1200\u001B[0;31m             \u001B[0manswer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msmart_decode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstream\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreadline\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1201\u001B[0m             \u001B[0mlogger\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdebug\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Answer received: {0}\"\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0manswer\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1202\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0manswer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstartswith\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mproto\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mRETURN_MESSAGE\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m/opt/conda/miniconda3/lib/python3.8/socket.py\u001B[0m in \u001B[0;36mreadinto\u001B[0;34m(self, b)\u001B[0m\n\u001B[1;32m    667\u001B[0m         \u001B[0;32mwhile\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    668\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 669\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_sock\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrecv_into\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mb\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    670\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0mtimeout\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    671\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_timeout_occurred\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;31mKeyboardInterrupt\u001B[0m: "]}],"source":["pdf_joy = df_result_joy.toPandas()\n","pdf_fear = df_result_fear.toPandas()\n","pdf_surprise = df_result_surprise.toPandas()\n","pdf_sadness = df_result_sadness.toPandas()"]},{"cell_type":"code","execution_count":24,"id":"fec68a18","metadata":{},"outputs":[],"source":["df_res_2.createOrReplaceTempView(\"vw_results\")"]},{"cell_type":"code","execution_count":null,"id":"5ebfb29e","metadata":{},"outputs":[],"source":["spark.sql(\"SELECT * FROM vw_results where tweet_id in ('1387861832124227587', '1387861855486554114', '1387861866635046914','1387861845336338434', '1387861855096344577', '1387861863698878464', '1387861871743668228')\").show()\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"03c4b3c6","metadata":{},"outputs":[],"source":["spark.sql(\"SELECT * FROM vw_results where tweet_id like '138796197812404%'\").show()\n"]},{"cell_type":"code","execution_count":25,"id":"b0d664a3","metadata":{},"outputs":[],"source":["pd_emotion_count = spark.sql(\"SELECT EMOTION, COUNT(*) as TWEET_COUNT FROM vw_results GROUP BY EMOTION\")"]},{"cell_type":"code","execution_count":37,"id":"a8cfa9ee","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["21/12/01 03:59:49 WARN org.apache.spark.deploy.yarn.YarnAllocator: Container from a bad node: container_1638330131916_0001_01_000008 on host: bigdatacluster2-w-0.us-east1-b.c.even-hull-328204.internal. Exit status: 143. Diagnostics: [2021-12-01 03:59:49.063]Container killed on request. Exit code is 143\n","[2021-12-01 03:59:49.063]Container exited with a non-zero exit code 143. \n","[2021-12-01 03:59:49.063]Killed by external signal\n",".\n","21/12/01 03:59:49 WARN org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 8 for reason Container from a bad node: container_1638330131916_0001_01_000008 on host: bigdatacluster2-w-0.us-east1-b.c.even-hull-328204.internal. Exit status: 143. Diagnostics: [2021-12-01 03:59:49.063]Container killed on request. Exit code is 143\n","[2021-12-01 03:59:49.063]Container exited with a non-zero exit code 143. \n","[2021-12-01 03:59:49.063]Killed by external signal\n",".\n","21/12/01 03:59:49 ERROR org.apache.spark.scheduler.cluster.YarnScheduler: Lost executor 8 on bigdatacluster2-w-0.us-east1-b.c.even-hull-328204.internal: Container from a bad node: container_1638330131916_0001_01_000008 on host: bigdatacluster2-w-0.us-east1-b.c.even-hull-328204.internal. Exit status: 143. Diagnostics: [2021-12-01 03:59:49.063]Container killed on request. Exit code is 143\n","[2021-12-01 03:59:49.063]Container exited with a non-zero exit code 143. \n","[2021-12-01 03:59:49.063]Killed by external signal\n",".\n","21/12/01 03:59:49 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 0.0 in stage 20.0 (TID 23) (bigdatacluster2-w-0.us-east1-b.c.even-hull-328204.internal executor 8): ExecutorLostFailure (executor 8 exited caused by one of the running tasks) Reason: Container from a bad node: container_1638330131916_0001_01_000008 on host: bigdatacluster2-w-0.us-east1-b.c.even-hull-328204.internal. Exit status: 143. Diagnostics: [2021-12-01 03:59:49.063]Container killed on request. Exit code is 143\n","[2021-12-01 03:59:49.063]Container exited with a non-zero exit code 143. \n","[2021-12-01 03:59:49.063]Killed by external signal\n",".\n","21/12/01 03:59:51 WARN org.apache.spark.deploy.yarn.YarnAllocator: Container from a bad node: container_1638330131916_0001_01_000007 on host: bigdatacluster2-w-1.us-east1-b.c.even-hull-328204.internal. Exit status: 143. Diagnostics: [2021-12-01 03:59:51.148]Container killed on request. Exit code is 143\n","[2021-12-01 03:59:51.149]Container exited with a non-zero exit code 143. \n","[2021-12-01 03:59:51.149]Killed by external signal\n",".\n","21/12/01 03:59:51 WARN org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 7 for reason Container from a bad node: container_1638330131916_0001_01_000007 on host: bigdatacluster2-w-1.us-east1-b.c.even-hull-328204.internal. Exit status: 143. Diagnostics: [2021-12-01 03:59:51.148]Container killed on request. Exit code is 143\n","[2021-12-01 03:59:51.149]Container exited with a non-zero exit code 143. \n","[2021-12-01 03:59:51.149]Killed by external signal\n",".\n","21/12/01 03:59:51 ERROR org.apache.spark.scheduler.cluster.YarnScheduler: Lost executor 7 on bigdatacluster2-w-1.us-east1-b.c.even-hull-328204.internal: Container from a bad node: container_1638330131916_0001_01_000007 on host: bigdatacluster2-w-1.us-east1-b.c.even-hull-328204.internal. Exit status: 143. Diagnostics: [2021-12-01 03:59:51.148]Container killed on request. Exit code is 143\n","[2021-12-01 03:59:51.149]Container exited with a non-zero exit code 143. \n","[2021-12-01 03:59:51.149]Killed by external signal\n",".\n","21/12/01 03:59:51 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 0.1 in stage 20.0 (TID 30) (bigdatacluster2-w-1.us-east1-b.c.even-hull-328204.internal executor 7): ExecutorLostFailure (executor 7 exited caused by one of the running tasks) Reason: Container from a bad node: container_1638330131916_0001_01_000007 on host: bigdatacluster2-w-1.us-east1-b.c.even-hull-328204.internal. Exit status: 143. Diagnostics: [2021-12-01 03:59:51.148]Container killed on request. Exit code is 143\n","[2021-12-01 03:59:51.149]Container exited with a non-zero exit code 143. \n","[2021-12-01 03:59:51.149]Killed by external signal\n",".\n","21/12/01 04:00:12 WARN org.apache.spark.deploy.yarn.YarnAllocator: Container from a bad node: container_1638330131916_0001_01_000009 on host: bigdatacluster2-w-0.us-east1-b.c.even-hull-328204.internal. Exit status: 143. Diagnostics: [2021-12-01 04:00:12.628]Container killed on request. Exit code is 143\n","[2021-12-01 04:00:12.629]Container exited with a non-zero exit code 143. \n","[2021-12-01 04:00:12.629]Killed by external signal\n",".\n","21/12/01 04:00:12 WARN org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 9 for reason Container from a bad node: container_1638330131916_0001_01_000009 on host: bigdatacluster2-w-0.us-east1-b.c.even-hull-328204.internal. Exit status: 143. Diagnostics: [2021-12-01 04:00:12.628]Container killed on request. Exit code is 143\n","[2021-12-01 04:00:12.629]Container exited with a non-zero exit code 143. \n","[2021-12-01 04:00:12.629]Killed by external signal\n",".\n","21/12/01 04:00:12 ERROR org.apache.spark.scheduler.cluster.YarnScheduler: Lost executor 9 on bigdatacluster2-w-0.us-east1-b.c.even-hull-328204.internal: Container from a bad node: container_1638330131916_0001_01_000009 on host: bigdatacluster2-w-0.us-east1-b.c.even-hull-328204.internal. Exit status: 143. Diagnostics: [2021-12-01 04:00:12.628]Container killed on request. Exit code is 143\n","[2021-12-01 04:00:12.629]Container exited with a non-zero exit code 143. \n","[2021-12-01 04:00:12.629]Killed by external signal\n",".\n","21/12/01 04:00:12 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 0.2 in stage 20.0 (TID 31) (bigdatacluster2-w-0.us-east1-b.c.even-hull-328204.internal executor 9): ExecutorLostFailure (executor 9 exited caused by one of the running tasks) Reason: Container from a bad node: container_1638330131916_0001_01_000009 on host: bigdatacluster2-w-0.us-east1-b.c.even-hull-328204.internal. Exit status: 143. Diagnostics: [2021-12-01 04:00:12.628]Container killed on request. Exit code is 143\n","[2021-12-01 04:00:12.629]Container exited with a non-zero exit code 143. \n","[2021-12-01 04:00:12.629]Killed by external signal\n",".\n","21/12/01 04:00:35 WARN org.apache.spark.deploy.yarn.YarnAllocator: Container from a bad node: container_1638330131916_0001_01_000010 on host: bigdatacluster2-w-1.us-east1-b.c.even-hull-328204.internal. Exit status: 143. Diagnostics: [2021-12-01 04:00:35.817]Container killed on request. Exit code is 143\n","[2021-12-01 04:00:35.817]Container exited with a non-zero exit code 143. \n","[2021-12-01 04:00:35.817]Killed by external signal\n",".\n","21/12/01 04:00:35 WARN org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 10 for reason Container from a bad node: container_1638330131916_0001_01_000010 on host: bigdatacluster2-w-1.us-east1-b.c.even-hull-328204.internal. Exit status: 143. Diagnostics: [2021-12-01 04:00:35.817]Container killed on request. Exit code is 143\n","[2021-12-01 04:00:35.817]Container exited with a non-zero exit code 143. \n","[2021-12-01 04:00:35.817]Killed by external signal\n",".\n","21/12/01 04:00:35 ERROR org.apache.spark.scheduler.cluster.YarnScheduler: Lost executor 10 on bigdatacluster2-w-1.us-east1-b.c.even-hull-328204.internal: Container from a bad node: container_1638330131916_0001_01_000010 on host: bigdatacluster2-w-1.us-east1-b.c.even-hull-328204.internal. Exit status: 143. Diagnostics: [2021-12-01 04:00:35.817]Container killed on request. Exit code is 143\n","[2021-12-01 04:00:35.817]Container exited with a non-zero exit code 143. \n","[2021-12-01 04:00:35.817]Killed by external signal\n",".\n","21/12/01 04:00:35 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 0.3 in stage 20.0 (TID 32) (bigdatacluster2-w-1.us-east1-b.c.even-hull-328204.internal executor 10): ExecutorLostFailure (executor 10 exited caused by one of the running tasks) Reason: Container from a bad node: container_1638330131916_0001_01_000010 on host: bigdatacluster2-w-1.us-east1-b.c.even-hull-328204.internal. Exit status: 143. Diagnostics: [2021-12-01 04:00:35.817]Container killed on request. Exit code is 143\n","[2021-12-01 04:00:35.817]Container exited with a non-zero exit code 143. \n","[2021-12-01 04:00:35.817]Killed by external signal\n",".\n","21/12/01 04:00:35 ERROR org.apache.spark.scheduler.TaskSetManager: Task 0 in stage 20.0 failed 4 times; aborting job\n"]},{"ename":"Py4JJavaError","evalue":"An error occurred while calling o483.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 20.0 failed 4 times, most recent failure: Lost task 0.3 in stage 20.0 (TID 32) (bigdatacluster2-w-1.us-east1-b.c.even-hull-328204.internal executor 10): ExecutorLostFailure (executor 10 exited caused by one of the running tasks) Reason: Container from a bad node: container_1638330131916_0001_01_000010 on host: bigdatacluster2-w-1.us-east1-b.c.even-hull-328204.internal. Exit status: 143. Diagnostics: [2021-12-01 04:00:35.817]Container killed on request. Exit code is 143\n[2021-12-01 04:00:35.817]Container exited with a non-zero exit code 143. \n[2021-12-01 04:00:35.817]Killed by external signal\n.\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2259)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2208)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2207)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2207)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1079)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1079)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1079)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2446)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2388)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2377)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n","output_type":"error","traceback":["\u001B[0;31m---------------------------------------------------------------------------\u001B[0m","\u001B[0;31mPy4JJavaError\u001B[0m                             Traceback (most recent call last)","\u001B[0;32m/tmp/ipykernel_8207/1283461929.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mpd_emotion_count\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshow\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m","\u001B[0;32m/usr/lib/spark/python/pyspark/sql/dataframe.py\u001B[0m in \u001B[0;36mshow\u001B[0;34m(self, n, truncate, vertical)\u001B[0m\n\u001B[1;32m    482\u001B[0m         \"\"\"\n\u001B[1;32m    483\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtruncate\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbool\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mtruncate\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 484\u001B[0;31m             \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jdf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshowString\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mn\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m20\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvertical\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    485\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    486\u001B[0m             \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jdf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshowString\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mn\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtruncate\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvertical\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1302\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1303\u001B[0m         \u001B[0manswer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgateway_client\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msend_command\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcommand\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1304\u001B[0;31m         return_value = get_return_value(\n\u001B[0m\u001B[1;32m   1305\u001B[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001B[1;32m   1306\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m/usr/lib/spark/python/pyspark/sql/utils.py\u001B[0m in \u001B[0;36mdeco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    109\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mdeco\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkw\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    110\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 111\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkw\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    112\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mpy4j\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprotocol\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mPy4JJavaError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    113\u001B[0m             \u001B[0mconverted\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mconvert_exception\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjava_exception\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py\u001B[0m in \u001B[0;36mget_return_value\u001B[0;34m(answer, gateway_client, target_id, name)\u001B[0m\n\u001B[1;32m    324\u001B[0m             \u001B[0mvalue\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mOUTPUT_CONVERTER\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mtype\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0manswer\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgateway_client\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    325\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0manswer\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0mREFERENCE_TYPE\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 326\u001B[0;31m                 raise Py4JJavaError(\n\u001B[0m\u001B[1;32m    327\u001B[0m                     \u001B[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    328\u001B[0m                     format(target_id, \".\", name), value)\n","\u001B[0;31mPy4JJavaError\u001B[0m: An error occurred while calling o483.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 20.0 failed 4 times, most recent failure: Lost task 0.3 in stage 20.0 (TID 32) (bigdatacluster2-w-1.us-east1-b.c.even-hull-328204.internal executor 10): ExecutorLostFailure (executor 10 exited caused by one of the running tasks) Reason: Container from a bad node: container_1638330131916_0001_01_000010 on host: bigdatacluster2-w-1.us-east1-b.c.even-hull-328204.internal. Exit status: 143. Diagnostics: [2021-12-01 04:00:35.817]Container killed on request. Exit code is 143\n[2021-12-01 04:00:35.817]Container exited with a non-zero exit code 143. \n[2021-12-01 04:00:35.817]Killed by external signal\n.\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2259)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2208)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2207)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2207)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1079)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1079)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1079)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2446)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2388)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2377)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n"]}],"source":["pd_emotion_count.show()"]},{"cell_type":"code","execution_count":26,"id":"97b6a787","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>EMOTION</th>\n","      <th>TWEET_COUNT</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>joy</td>\n","      <td>688</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>fear</td>\n","      <td>1143</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>surprise</td>\n","      <td>211</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>sadness</td>\n","      <td>193</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    EMOTION  TWEET_COUNT\n","0       joy          688\n","1      fear         1143\n","2  surprise          211\n","3   sadness          193"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["pd_plot_emotion = pd_emotion_count.toPandas() \n","type(pd_plot_emotion) \n","pd_plot_emotion.head()"]},{"cell_type":"code","execution_count":38,"id":"837b0a5e","metadata":{},"outputs":[{"data":{"text/plain":["<matplotlib.patches.Circle at 0x7ff859bf5dc0>"]},"execution_count":38,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAQIAAADnCAYAAAD1sVjVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAquklEQVR4nO2deXyU1dXHv2cmk5CwBDAEwiaIYUvCsCOCLCpIEQUBdYgV0FepVV+XNgp1i0FrtU7r9tZatRbF1ggq4FZFVJRVFk1YBEEFRRI2gQDZZ+a+fzwTJGxZmGeeWe7385mP8cl9zj1D5vnNXc49R5RSaDSa6MZmtQMajcZ6tBBoNBotBBqNRguBRqNBC4FGo0ELgUajQQuBRqNBC4FGo0ELgUajQQuBRqNBC4FGo0ELgUajQQuBRqNBC4FGo0ELgUajQQuBRqNBC4FGo0ELgUajQQuBRqNBC4FGo0ELgUajQQuBRqNBC4FGo0ELgUajQQuBRqNBC4FGo0ELgUajAWKsdkBTM0U5OfHA2f5Xh2N+bgc0OK65nOLnUqAQKPC/CoEdwPfAjsTsbF0EM4oRXQQ1dCjKyUkGhgL9gI788uC3MLnrMgxB+Bb4BlgBfJ6Ynf2zyf1qQgQtBBZSlJOTgvHgV726WetRNRSwEfis6pWYnb3HWpc0ZqGFIIgU5eS05ZeHfhiQaqlDdWcz1YWhwGJ/NAFCC4HJ+L/1JwG/BnpZ7E6gWQb8C5iTmJ19OFidisgRpVSjYPUXDWghMAGn29Xov8Wdr2iIfQownMjfnSkB3sAQhc/MXnjUQhB4tBAEEKfb1Rv4DTDptvKWGyZ6mg+02icL2Aa8DMxKzM7+wYwOROQI0Bj4M/ArjPWMh5VSr4vIbOANpdQCf9t/A68rpd42w5dIQQvBGeJ0u2zAVUAW0KfqepIvZs1bpal9LXPMehTwKfAixtTBGyjDfiGYAtwEjAKSgNXAAKAzcKdSapyIJAJ5QKpSyhOo/iMRLQT1xC8AVwP3c7LVfoV3bum5e1oqR0qwfQtBNgMPAG8EYtrgF4IXgPVKqZf812YDc5VSb4vIBuBCYDxwrlIq60z7jHQife4acJxul83pdk0CNgD/4VRbfoL9Rcfeb4LpWwjTFZgDrCnKyflVgGzKaX43G7gGuA5j3UJTA3pEUEuOmQLcD3SvzT0xSrZ/UtK1g5l+hSlLgHsSs7OX1udm/4hgMsZ6zGigObAGGKCU2iUiLYFVwC6l1IAA+RzR6BFBLXC6XcOBdcBr1FIEADyiOqy0H1lnmmPhywXAkqKcnP8W5eTUaUtVRGKAcmAext8kH/gEuFsptQtAKbUb2IQeDdQaPSI4DU63qznwF2BqfW2keuOW/LPsnAsC5lTkoTC2HrMSs7N/rKmxiDiBF5RS/U/TJgFYD/RWShUFzNMIRo8IToHT7crEWOSaeiZ2ttrKe5XiKw6IU5GJAFcCG4pycn5TlJNzyrm/iNyEMSq77zRtLsb4uz2jRaD26BHBcTjdro7A34FLAmXz+oqkpVMrWwwOlL0I5xPgfxKzs7db7Ug0oYXAj9PtsgN3AjlAQiBtN1H2/HdLOjsDaTPCKcaYKjxntSPRghYCwOl2tcTY3hpiVh+vlJzzQwcVd7ZZ9iOUBRijA30c2mSifo3A6XadD3yJiSIA8Hzsnm1m2o9QxgLrinJyLrTakUgnqkcETrfrVuCvgMPsvmyKwk9Kura0IVEvvvXABzwG3KszKZlDVAqB0+1KAP6BcTQ4aDxQ1nrtxd7EPjW31JyCucC1idnZ5VY7EmlE3beT0+3qhJGKK6giAPCv2H36A3xmXAksLMrJaWa1I5FGVI0I/BGCbwFNLXFAUf5uSefSJtjr3b8kJCCNG2Nr3Bhp1Ahb48bYEhMhLg5sNsRuN7ryesHnQ5WXow4exHfkCOrwYXyHD6MOH0aVlgbqXVnB18CvahOApKkdUSMETrdrLPA6EGelH1dVNv/81oqWNS9M2u3YW7bE3ro19nbtsLdti61pU/B6wetFAWKzQUyM8d/ToLxe8HhQShkndWJiQATfwYN4f/oJz48/4i0sxLd7N/h8gXibwaAAGJ2YnZ1vtSORQFQIgdPtmgL8E7Bb7Uu8kk0flnQ98cSizYa9fXsc3bsT06mT8S1fWWl8y8fGmuqTqqgwBMDhwHfwIJ6tW6nctAnvjh0Q2p+PQ8CExOzsRVY7Eu5EvBD4dwae5vTHVoPKP0o7bO3mi08lLg5HaiqO9HRiOnY0HsbY2Bq/4c1G+XxQUQE2G5Xffkvlxo14vv3WuBZ6VALXJ2Znv2q1I+FMRAuB0+26HXjSaj+OxSbCb1KHrb+hxyUZ9rZtwetF4iydrdSIKiuDmBg8P/xAxfLleL7/3mqXjkdhRCL+1WpHwpWIFQKn23UnRoxASNA0vjHjMy7k131GE++IVQmx8SEzQqktSimoqECVl1O+YgUVeXlQVma1W8cyOTE7e7bVToQjESkE/unAM1b7AdC5RXumnTeeIZ1641OKeEdof/vXFlVRASJUbt5M+eef49u3z2qXwJgmXJqYnf2R1Y6EGxEnBE63awxGjLqlE+02icn8ftivGdTBicMeg91m+TqlKVRtU1Zu3kzZokWoQ4esdukwMCQxOzvPakfCiYgSAqfb5QSWApblvG+ekMgtg65iTPfB2G12HPboqDNbJQgVX35J+WefWR2nUAgMNCudeiQSMULgdLtSMPLUtbWi/7gYB9POG881fUZjEyEuxtwtv1BFVVaCUpQvW0b50qVWxiVsAgYlZmcfsMqBcCIihMB/duBzjqkrEEwyUs7FfdmdJMY3ipg1gDNFVVTgO3KEkrlz8e3aZZUbS4ERidnZIbWiGYqEvRA43S4B3gSuCHbfcTEObr8gk/E9LtQCcBKUUuDxUP7FF5R/+qlVo4M3gasSs7PDJmTSCiLh0NFjWCACGSnn8vb1T2oROA0igjgcxPXvT6NbbsHWqpUVbkwA/mhFx+FEWI8InG7XeAzFDyo3n38lk/uN0QJQB6pGB2WLF1OxfHmwu/cBwxOzsz8PdsfhQtgKgdPtaoWRsjopWH3GO+L485jb6duuOwmxDYLVbUShKiqo3LKF0vnzjQNUwWM70COY5dvDiXCeGrxIEEUgpUkSr09+lP7t07QInAESG4ujc2ca3Xgj0iiou7wdCLFw81AiLEcETrfrRuD5YPXXq01XnrniLuIdDYixR2ZgULBRXi+qvJySf/8bb0FBMLsem5idrUukH0fYCYHT7ToHo8xVUL5ORncdRPYl02ig1wNMQVVUUPLWW3i+CVq92D1ARmJ29p5gdRgOhNXUwF97YDZBEoErMobzgBYBU5HYWBImTMDRvdYlJc+UZII4mgwXwkoIgLuB84PR0VXOi5l+4dSo2hkoKyujf//+OJ1O0tLSyM7OBmD//v2MGDGC1NRURowYwYEDJw/We+KJJ0hLSyM9PZ1JkyZR5j+ZOH36dHr06MHkyZOPtp09ezZPPfUUAOJwED9uHI6MDJPf4VHGFuXkXBeszsKBsBECp9uVCjwYjL6uyBjO74ZdG1UiABAXF8cnn3xCfn4+eXl5fPDBB6xcuZJHH32Uiy66iK1bt3LRRRfx6KOPnnDvzp07efrpp1mzZg0bNmzA6/WSm5tLUVERy5cvZ926dXi9XtavX09paSmzZs3i5ptvPnq/OBzEX3YZjrS0YL3dJ4tycnTBGT9hIwQYgUOmB/Bf2m0wM6JsJFCFiNDIv5JfWVlJZWUlIsKCBQuYMmUKAFOmTGH+/Pknvd/j8VBaWorH46GkpITWrVtjs9moqKhAKUVpaSkOh4PHH3+c2267DYejejkJcTiIHzuWmK5dTX2ffppgZK7SECZC4HS7BhOE6MG+7brzwMgbo3pNwOv10rNnT5KTkxkxYgQDBgxg9+7dpKSkAJCSksKePSeus7Vp04asrCzat29PSkoKiYmJjBw5ksaNGzNhwgR69epFx44dSUxMZPXq1YwdO/ak/YvDQcIVV2Bv3drU9+nn8qKcHFMrXIULYSEEgNvsDtoktuCpcVlRLQIAdrudvLw8fvrpJ1atWsWGDRtqdd+BAwdYsGAB27Zto6CggOLiYl591UgjePfdd5OXl8df/vIX7r//fmbOnMmLL77IVVddxcMPP3yCLYmNJeGaa4IVZ+A+XSn2aCHkhcDpdl0FDDCzjwRHA56/8r6onA6ciqZNmzJs2DA++OADWrZsSWFhIQCFhYUkJyef0H7RokV07NiRFi1a4HA4GD9+PMuPCyX+6quvAOjcuTOvvPIKc+bMYcOGDWzduvUEexIXR8NrrzVSr5tLP8BldiehTkgLgdPtigX+ZGYfguC+/E6SGjWL2CxCtWXv3r0cPHgQgNLSUhYtWkTXrl25/PLLefnllwF4+eWXTzqsb9++PStXrqSkpASlFB9//DHdulXP2l41GqisrMTrDy+22WyUlJScYE/sdmzNmhE/blxg3+TJeaQoJyc6E0j4CWkhAG4BzjGzg1svuJpebbrQIEoTiRxLYWEhw4cPp0ePHvTr148RI0YwZswYZsyYwUcffURqaiofffQRM2bMAKCgoIDRo0cDMGDAACZOnEjv3r3JyMjA5/Mxbdq0o7bnz59Pv379aN26NU2bNmXgwIFkZGQgIjidzpP6Iw4HjtRUYgcNMvutdwCuN7uTUCZkIwudbldT4DuguVl99GvXnWfGT9dTghBHVVZSPGuW2aHIPwKpidnZIVm8wWxCeURwCyaKQLwjjkfH3KZFIByIiSH+yivB3HMe7YniUUFICoF/beBWM/u4a/hkGsXGm9mFJkCICLaEBOIuvNDsrv4QrWsFISkEQCZgWjqbfu26M7rb4KjfKgwnJDaWuH79zI4vaA9cY2YHoUqoCsHvzDKspwRhTEwMCeZPEf7HTOOhSsgJgdPtGgqYdvrktgsm6SlBmCIiSEICcUNMDQYcVJST09nMDkKRkBMC4LdmGW7V+CzGZ1yopwRhjMTGEnfeeUhCgpndTDXTeCgSUkLgdLuSMfFMwZ1DrsFucclxTQCw2YgbPtzMHiYX5eREVXRZqD0V12PSCcNOZ7Vl2Ll9o6YEWSQjMTHEOp1I06ZmddEGGGGW8VAk1ITg12YZvmv4ZBw632DkYLPRYISpz2pUJS4JGSFwul3nAqZkpeiRkkrPNl2i/ixBJCF2O47UVGwtW5rVxdiinJxmZhkPNUJGCIBxZhm+dfDVxMU4am6oCS/sdhoMHWqW9TiMeJaoIOKFoHWTFvRs0xmbhNJb1QQCsdmIOfdcM3cQomZ6EBJPh9PtagkMNMP21T1HAFGfdyKiie3d2yzTfYpycjqZZTyUCAkhAC7HBF8c9hgmOi/W04IIRhwOYs87D8Q0sTdt7hFKhIoQjDPD6MWpAxA9Goh4JCaGmHPPNcu8FoJg4HS7GgEXmWH7uv6X0zBOhxNHOhIXR5x5yUu0EASJ4RgrtAGlVeOz6NA8JdBmNSGKvU0bJN4U0T87GuofhIIQ9DfD6NBOffApnxmmNaGI10tMaqpZ1iN+VBAKQtDPDKOXdh9MvEOXL48WJC4OR3q6Wea1EASBvoE22DA2nm7JHQNtVhPixHToYFaugmFmGA0lLBUCf4nzswJt9/wOPajwVgbarCbU8XoNMQg85xTl5LQ1w3CoYPWIwJRpwSVdzqdRnKnn1TWhSGysmeXVI3p6YLUQBHxaADDg7KBV1NWEEFUhxyZhSuRrqGC1EAR8RHBWQiJxulhJ1CING0KsKX//iF50skwInG6XAAEPEu/e6hy9PhDFqMpK7K1MSYAd0bEEVo4IWgKNA200reU5NIjROQmjFbHbsaeYEkimhcAkTElQ37ddd52OLIoRhwO7OTsHjYpycgK+wxUqRJwQdEmOaOHW1IIY84qgROyHy0ohaBNog00aNNSpyjVIo0ZmBRZpITCBgMt2cqPmVHj0QmHU4/EYYhB4tBCYQMBHBC0aNiNUy7xrgofy+bA1Dvg6NGghMIWAjwhaNGqmC5hoEEC0ENSJiBKCpIZNidXBRBq7HZueGtQJq+MIAkrbpsnE6NoFmpgYpEkTMyybYjQUsFIIAp4soHWTFoE2qQlDRARbM1Nqk0RsFlwrhSDg/6gNY3UiEo2BxJmyjayFwAQC/o+qS5ppjmLOonHELkBpIdBEJGKOEETsiCCigvJ1DQNNFbuT2nhmX3bzoUDaFNSR6YE0GEJYKQQeAqywXp83kOY0YUylUjGINA+kTUXkFtC08o0F/Kn1+DyBNqkJU3zmBJhG7DeNlUIQ8Ke2tLIi0CY1YUqlOUpQYobRUMBKISgOtMFdh/cF2qQmTCkqN+XL+4AZRkMBK4VgV6AN/nRwD16frm4U7Xh8ikOVpnwO9pthNBSwUggKA21wb/EByj16ehDteJXiiDlCoEcEJhB4IThyQO8caFAKLQR1JKKEYF/xQRAdSxDt2MQ0IdBTAxMIuBDsOXKAWJ24NOqJsQnFHlOEYKcZRkMBK4WgINAG95cU6cXCEOeJJ54gLS2N9PR0Jk2aRFlZ2QltFi9eTM+ePUlLS2PoUKPS2N69exk8eDDp6enMnz//aNuxY8dSUFD9o1TmUZgzIOA7U6yGABE1IgD4bt8OM8xqAsDOnTt5+umnWbNmDRs2bMDr9ZKbm1utzcGDB7n55pt5++232bhxI3PnzgXgtddeY8qUKaxYsYLHH38cgHfeeYfevXvT+risxbtKTQssi1ghsHIcbYoQrPlpE91bddIpy0IUj8dDaWkpDoeDkpKSEx7i//znP4wfP5727dsDkJycDIDD4aC0tJTy8nJsNhsej4cnn3ySd955p7p9n+LHI6YksFXA92YYDgWsfFp2YEKk1vrCbymtPHG4qbGeNm3akJWVRfv27UlJSSExMZGRI0dWa7NlyxYOHDjAsGHD6NOnD6+88goAmZmZfPjhh4waNYoHH3yQZ599lsmTJ5OQUL3qtUcpdpWYMiIomNErKWI/WJYJQX5WrhfIC7TdTbu36ePIIcqBAwdYsGAB27Zto6CggOLiYl599dVqbTweD2vXruW9997jww8/5KGHHmLLli0kJiby3nvvsWbNGnr37s27777LhAkTuPHGG5k4cSIrVqwAIEbELCGI2GkBWF8NeU2gDRYc2qtTmocoixYtomPHjrRo0QKHw8H48eNZvnx5tTZt27Zl1KhRNGzYkKSkJIYMGUJ+fn61NjNnzuTee+/ltddeo0+fPrz00kvcc889AFR4FWVeU/7+eWYYDRWsFoK1ZhhdV7gVgA4dOpCRkUHPnj3p27cvAHPnziUtLQ2bzcaaNafWoeuvv57k5GTS09OrXZ8+fTo9evRg8uTJR6/Nnj2bp556yoR3Elm0b9+elStXUlJSglKKjz/+mG7dulVrM3bsWJYsWYLH46GkpIQvvviiWputW7dSUFDA0KFDKSkpwWazISJHdx9MWh8AWG2W4VDAaiEI+IgA4P1NSymuKAXg008/JS8v7+hDn56ezltvvcWQIUNOa2Pq1Kl88MEH1a4VFRWxfPly1q1bh9frZf369ZSWljJr1ixuvvlmM95KRDFgwAAmTpxI7969ycjIwOfzMW3aNJ577jmee+45ALp168aoUaPo0aMH/fv354Ybbqgmxvfeey8PP/wwAJMmTWLWrFmcd955ZGVlUe71selAuVnuR7QQWB19sxnjFGLDQBpd8v1X3HfxDSf93fHfQKdiyJAhbN++vdo1m81GRUUFSqmjK9+PP/44t912Gw5HxGaxCig5OTnk5ORUu3bTTTdV+/+77rqLu+6666T3z5kz5+jPycnJ1aYWHp9i22FTRgSHgC1mGA4VLB0R5Gfl+oCvAm13f8khfjhQiIgwcuRI+vTpw/PPP3/Gdhs3bsyECRPo1asXHTt2JDExkdWrVzN27NgAeK05U3aVeKgwJw/B2hm9kiJ64cnqEQEY6wSDA230/U1L+eSzT+nYvgN79uxhxIgRdO3atcYpQU3cfffd3H333QDccMMNzJw5kxdffJGFCxfSo0cP7rvvvkC4r6kjFV4fG82bFqwyy3CoYPUaAcBKM4x++u0aWqW0Aowh5BVXXMGqVYH7e371lTGQ6dy5M6+88gpz5sxhw4YNbN26NWB9aGqPTYRvi0w7gv6xWYZDhVAQgg8xIW3Zd7t+ZMduI3ixuLiYhQsXnrADcCbcf//9zJw5k8rKSrxe4+izzWajpCRis1mFNAfKvRw254BBGbCkNg1F5F4R2Sgi60QkT0QG1PK+DiKy4Yy8PEMsF4L8rNwD1PIfui5UHi5j6NAhZPhXny+99FJGjRrFvHnzaNu2LStWrODSSy/lkksuAaCgoIDRo0cfvX/SpEkMHDiQb775hrZt2/LPf/7z6O/mz59Pv379aN26NU2bNmXgwIFkZGQgIjidzkC/FU0NlHt9rNxdapb5pbWJKBSRgcAYoLdSqgdwMUb0bFggoRB843S7bgeeDLTdhrHxfPLb52jgMKX8lSZEKPf6eHr9fsyJI+L3M3ol/bWmRiIyHrhOKXXZcdcfAC4D4oHlwG+UUkpE+gAvYYTZLwV+pZRKF5GpwOVAAtAJmKeUuttvaySQA8RhRDpep5Q6IiKP+u/xAAuVUlkiciWQjZF5uUgpddrFMctHBH7eNsNocUUpH2xeQaVXpzmPVDw+Rf7PZWaJAMD7tWy3EGgnIltE5FkRGeq//n9KqX5KqXQMMRjjv/4v4Dal1MCT2OoJXA1kAFeLSDsRSQLuAy5WSvXGiMH5nRi1G64A0vwjkYf9Nh4ALlFKOTFE4rSEhBDkZ+VuA9abYfvVte/j0enLIhYFrN1r2lmgLTN6JW2ulR9KHQH6ANOAvcDr/m/34SLyhYisBy4E0kQkEWiqlPrMf/vs48x9rJQqUkqVAV8DZwPnAd2BZSKSB0zxXz+EsY7xon9UUrVItQyYJSI3AjUevgmF7cMqFmAoYEDZuu9HfjxQSJfkDoE2rQkBCks8FFWYlozmP3VprJTyAouBxf4H/zdAD6CvUmqHiDwINAAEQ8NOxbH7oF6M51SAj5RSk45vLCL9gYsAF3ArcKFS6ib/YuWlQJ6I9FRK/XyqDkNiROBngVmG/7ZsLiUVEXuCNGqp8CqWFZq6S/Pv2jYUkS4iknrMpZ7AN/6f94lII2AigFLqIFAkIlXxM9fUoouVwCAROdffX4KIdPbbTVRKvQ/c4e8XEemklPpCKfUAsA9odzrjoTQiWIuRE65NoA1/9t1adhzcTZfkswNtWmMRPqXYU+rhBxMPGc3olfRtHdo3Ap4RkaYYi3bfYkwTDmJMe7dT/bzCdcBLIlKCsYV+WpRSe/1TjddEpGr1+z7gMLBARKpGGnf6f/e4X5gEIw4in9MQErsGVTjdrkeAP5hhu1ebrvx94gziHQ3MMK8JMpU+xatbDrK71LT1nztm9EqKmiOloTQ1AHiB08+d6s1XOzezYdf3OrlpBOD1KbYfqjBTBLzA62YZD0VCSgj8uwcLzbL/2MezqPSaNpTUBAkf8PHOgJfOPJYFM3olBbwkXyhToxCIiNcfLln16mCyT/8wy/DWfT+ydFseFVoMwhavz+vbvL/Md9C8nQKAqJkSVFGbEUGpUqrnMa/tZ9KhiNS0QPk28MOZ9HE6Hln0EhUeHWAUrtgri2zJK0dva+A9cNrFrzMgb0avpM9Nsh2y1GtqICJ9ROQzEVkrIh+KSIr/+o0islpE8kXkTRFJ8F+fJSJ/FZFPgcdOZ9uf1PSZ+vhVG34uKeLhj17U24lnwFNPPUV6ejppaWk8+eSTp2y3evVq7HY7b7zxBlC3IiUnxVMMK6fQ8tDiTnds6ewcuufhZaK8e8/w7RyPaZ+9UKY2QhB/zLRgnog4MP6xJiqlquKl/+hv+5Y/nNIJbAL+5xg7nTHCI39fiz5fwNgWMYX/bl5GXsEWPUWoBxs2bOCFF15g1apV5Ofn8+6775706LXX62X69OlHD3VB3YqUnICnDAr+CzvfPXpp4M9PDbp9S+fYdsXLP8cI5jlT9lHHIKJIoa5TgyuALkA68JE/1PE+oK2/bbqILPFHVV0DpB1jZ66q5R8rPyv3EIbAmMZ97/9NTxHqwaZNmzjvvPNISEggJiaGoUOHMm/evBPaPfPMM0yYMOFogRI4dZGSU6Ulq4a3BFZNO+FyA9+hxGt+HDvk2u2jvo3zFp1pmPozkVy74HTUZ2ogwMZjxCFDKVVVpWIWcKtSKgPjlNSxm/Z1XeZ9DBMKoFShpwj1Iz09nc8//5yff/6ZkpIS3n//fXbsqH7adufOncybN++EXIS1LVJyAv4pARWnrkrepuzLLndsOTd98N7HlqJ8++rx1vZjwgnYcKE+QvAN0MJ//hoRcYhI1Td/Y6DQP32oTdjkKcnPyi0Eajz+eSb8d/Mylm77irJK01JcRRzdunVj+vTpjBgxglGjRuF0OomJqb7+e8cdd/DYY49ht1c/61LbIiXV8BTDD7nVpgSnQkAG73MPvn1Ll5g2Jas+R6m6bC08PqNX0qE6tI8oaowsFJEjSqlGx13rCTwNJGKEKT+plHpBRH4L3I2x6r8eaKyUmiois4B3lVJv1MU5p9vVGOPcdYu63FcXYu0OXrv2Ec5uloJDl1SvM/fccw9t27atls69Y8eOR4vM7Nu3j4SEBJ5//nnGjRt3tM2dd97JuHHj2LJlC16vl8zMTMaOHcunn376i3FvORzMh4WDQNV9GvdTfP9Nc9q95quwN0mroeke4JwZvZJMDU4IZWocERwvAv5reUqpIUopp1IqTSn1gv/635VSHZVSw5RS/6uUmuq/PrWuIgCQn5V7GJhZ1/vqQoW3kpvmPqKnCHVgz549APz444+89dZbTJpU/UDctm3b2L59O9u3b2fixIk8++yz1USgpiIlACifMRVYPLpeIgDQtnRVtzu3dOo+cN9fl6B8+0/T9NFoFgEIscjCU/APwNSMoHuLD3DLm49SqqcItWLChAl0796dyy67jL/97W80a9asWpGSmjhdkZKjeEvh05FQfsqTs7VCQIbu/dMFt23tKimlXy45yXRhB/D3M+okAgipQ0enwul2TQTmmt3PmO4XcN+IG4jXqc2sxVMCy6+Bn+YH3PQPCYM2vtn2VamwN+ruv3TVjF5Jpn+2Qp2wEAIAp9u1EqhVVtgz4ZZBV3Ftn9HEx+pTipbgKYb1M2HTn03rQiG+xS3uW7am+bQDd/Vpq6vTEF5CMAgj27GY3dfvh13LlT0u0mIQbDzF8PWfYYOpy0JVVAI9yVRfB6OzUCcc1ggAyM/KXYaxU2E6f1k8mwUbP9MLiMHEUwzfPB0sEQB4XIvAL4SNEPiZgVE41XT+9PG/eGPdx1oMgoGnGDY9Dvn3BKvH7/gl26+GMJoaVOF0u/ph5IcPyqb/LYOu4tq+o3VmI7PwFMP6h2DTac+iBRIvMIRMtbzGllFEuI0IyM/KXQ38KVj9/W3ZHB5Z9C+9tRholM8QgRVTgykCAH/UInAiYScEfh4CvgxWZ29v/Iwb5zxEUdkRXSwlEHgroHwffDQYdtQ5zuxMWInJAWrhSthNDapwul1pGJmPg7bpn9yoOf+48l5aN0nSZdTqi6cYDm2BTy+B8kCnEjgtRzB2Cb4LZqfhQriOCMjPyt0I3BvMPvcc2Y9r9gyWbcvXi4j1wVMMO+bBwgHBFgGA27QInJqwHRFU4XS7/gOcUP3FbMZ0v4B7Lr6eWLtDH1aqCW85eMvgixuCPRWo4kUy1Y1WdBwuhO2I4Biux5j7BZV3v17C2H/+jq92fqNHB6fDcwR2LYJ3Uq0SgSXAzTW2inLCfkQA4HS7WgJfYBSFDDp6dHASrB8FgFFdqD+ZKujzkHAjIoQAwOl2ZWBUgG1sRf8tGjbj/pE30L99OnF2BzZbJAy26oHPC75yKHgPVt9ixVpAFUeA88lUplTZjjQiRggAnG7XpRjp0C17CtNancOMC6dyblJ7EqLtrIKnGH5eBWtvh4OWPn8KuIJMZVph3UgjooQAwOl23YnJKc5qw4D26fzhouto2bg5CbHxVrtjLpVH4Mj3sOYW2LvUam8Afkumql1yBA0QgUIA4HS7ngb+12o/BGFElwH89vwradX4LOJiHNht9ppvDAM8Xg+VPi+VJbuKm+Td1pCdb1vtUhW/I1M9YbUT4UakCoEA/0cIrRantTqHa/tcyvDUfiilwjb5SUlFGTaxsXDLCl5d8z7b9n5f9kXKG4dtYl5eyTpwP5lKHyaqBxEpBBCaYgDQpEFDxqUPY3LfMSTENsBhjyHW7rDardNS4anE4/NyqKyYWavf4Z2Nn3GkovTo7//YdOXiMQk/DLPMQYNHyFRBDTCLJCJWCOCoGDwD3GK1LyejW8uOXJjaj191HURyo2b4fIr42NAYKZRUlGG32Sg4tI8PNi3jk29Xs2Xvjydt21gqipa0mmcTsWbHBvgrmbWqoKU5BREtBFU43a5HgD9Y7cfpaNX4LIZ06s2l3QbTveU5VPo8oCA+Ng6bmLsJ4lM+SivKERHsNhsbCr/jvU1L+fy7L9lbfOqiIsfy3FmLPxsYt3uoqY6enAfIVA9Z0G9EERVCAOB0u+6mhgKsoYJNhA7NW9O95Tk4W3emV5sunN0sBY/Pi8fnxSaCwx5DXExsneyWeyqo9HpQSmG32bHbbGzbX8BXP21mXeFWvt69jR/2F6Ko+2cixV5c+N/kd5NECNY8xwfcSqaK+gzEgSBqhADA6XbdADwLQfuwBgybCG0Sk2nRqBktGjYjqWFTWjY+i3ZNW9KycXPiYmKx2+zE2OygFB7lw+vzUlZZzq7D+9lZtJtdh/ezr/gAe48cYM+RAxQU7a3XQ38q5rT4cGkXx8HBATN4akqBTDLV/CD0FRVElRDA0SSoc4EUq32JNDrHHPhuTouF54iYmmB2L3AZmeoLE/uIOqIuDtafBLUPRjiyJoBs8TTrVOhNWG1iF6uAvrUVARG5V0Q2isg6EckTEVPS4YvI+yLS1AzbwSLqhACOFlgdjjFN0ASQmUX9zAqj/DtwAZnq5FsXx+Ev0jsG6K2U6gFcjFHVqDb31urkmBjYlFKjlVIHa3NPqBKVQgCQn5VbmZ+VewtwHaDPEQeIFeWtMop8jnUBNFkC/JpMdTOZqqIO96UA+5RS5QBKqX1KqQIR2S4iSQAi0ldEFvt/flBEnheRhcArIjJVRBaIyAci8o2IZPvbdRCRTSLyLEa6vHZVNkWkoYi8JyL5IrJBRK7239NHRD4TkbUi8qGIhNy0NGqFoIr8rNxZwGCMCs6aAOAu6hUoYf0GGECm+nc97l2I8ZBuEZFnRaQ2W5t9gLFKqUz///cHrgF6AleKSF//9S7AK0qpXkqpYz83o4ACf3HgdOADEXFgxLJMVEr1AV4C/liP92MqUS8EAPlZuWsBJ0bB1ehaPTWBt0s79CtTtm/PwIQP4+BYLzLVhvoYUEodwXiwp2EsML4uIlNruO1tpVTpMf//kVLqZ/+1tzC+MAB+UEqdLBnOeuBiEXlMRC5QShVhiEY68JGI5AH3AW3r857MRGfR8JOflVsE3OR0u/4NvIDxB9TUC5EXDqft+t8m68+tx82bgevJVCvO1AullBdYDCwWkfXAFMDDL1+Ax58TP740+vFfCuoU7ar62yIifYDRwJ/804x5wEal1MB6vYkgoUcEx5GflbsEY3TwMEZ9PE09mHWk6wCPkoI63OLFCPjqFQgREJEuIpJ6zKWeGNO/7RgjBYAJNZgZISLNRSQeGEcNO00i0hooUUq9CriB3hjTmxb+xUtExCEiaXV7N+ajheAk5Gflludn5d6P8YfU+9X1wIPN8UZJp621bP4FMJBMNYNMFaj1hUbAyyLytYisA7oDDwI5wFMisgRDfE7HUmA2kAe8qZRaU0P7DGCVfwpwL/CwUqoCmAg8JiL5flvn1+cNmUnUBRTVFafbZQNuBbKB5ha7E1bEi6d4eas3K2xCs1M02Y5xBuR1MkPrg+hfT+irlLrVal+CgR4R1EB+Vq4vPyv3aaAj8ABw0FqPwodSFdPwk7I2+Sf5VREwHehKpsoNNRGIRvSIoI443a5E4E7gDiDRWm9Cn+a2sn2ftFzQUIR4jHiN54GHyFT7LHZNcwxaCOqJ0+1qBvwOuB2LMieHC881X7xwYIPdeRh5A3Zb7Y/mRLQQnCFOt6s5hiBMg5BI1xVK7MAIpnnevz2rCVG0EAQIp9sVC4wHbgKsSNARSqzAEIC5+Vm5unx0GKCFwAScbldXjOCVXxOCUWQmsQ7IBXLzs3K3We2Mpm5oITAR/9bjcOBa4FIgyVqPAs53wGvAa/lZuV9b7Yym/mghCBJ+UegNjPS/zif8MiX5gHzgE+D1/KxcM3MPaIKIFgKLcLpdjTBGCyOBS4DU099hCeUYyUCW+F/L87NyD1nrksYMtBCECP6KzulAmv9V9XOwYhUOAd9jDPe/BD4HVudn5ZYHqX+NhWghCHGcblcbfhGHFIww52bHvZpz6liGCuAwRnXgw8DP/PLAH/1vflauDvCJYrQQRAhOtysGaIIxj/dgnJz05Gfl1nSwRqPRQqDRaPShI41GgxYCjUaDFgKNRoMWAo1GgxYCjUaDFgKNRoMWAo1GgxYCjUaDFgKNRoMWAo1GgxYCjUaDFgKNRoMWAo1GgxYCjUaDFgKNRoMWAo1GgxYCjUaDFgKNRoMWAo1GgxYCjUaDFgKNRoMWAo1GgxYCjUaDFgKNRoMWAo1GgxYCjUaDFgKNRgP8Pw6/cinVvzENAAAAAElFTkSuQmCC\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["import matplotlib.pyplot as plt\n"," \n","\n","names = ['Joy', 'Fear', 'Surprise', 'Sadness']\n","size = [688,1143,211,193]\n"," \n","\n","my_circle = plt.Circle( (0,0), 0.75, color='white')\n","\n","plt.pie(size, labels=names, colors=['lightcoral','seagreen','orange','skyblue'], autopct='%1.1f%%')\n","p = plt.gcf()\n","p.gca().add_artist(my_circle)\n"]},{"cell_type":"code","execution_count":51,"id":"8f42a34e","metadata":{},"outputs":[],"source":["pd_emotion_over_time = spark.sql(\"SELECT EMOTION, CAST(CAST(month_year AS STRING) AS DATE) AS MONTH_YEAR, COUNT(*) as TWEET_COUNT FROM vw_results GROUP BY EMOTION, month_year\")\n"]},{"cell_type":"code","execution_count":52,"id":"912866bc","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>EMOTION</th>\n","      <th>MONTH_YEAR</th>\n","      <th>TWEET_COUNT</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>surprise</td>\n","      <td>2021-04-01</td>\n","      <td>211</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>fear</td>\n","      <td>2021-04-01</td>\n","      <td>1143</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>sadness</td>\n","      <td>2021-04-01</td>\n","      <td>193</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>joy</td>\n","      <td>2021-04-01</td>\n","      <td>688</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    EMOTION  MONTH_YEAR  TWEET_COUNT\n","0  surprise  2021-04-01          211\n","1      fear  2021-04-01         1143\n","2   sadness  2021-04-01          193\n","3       joy  2021-04-01          688"]},"execution_count":52,"metadata":{},"output_type":"execute_result"}],"source":["pd_emotion_over_time = pd_emotion_over_time.toPandas() \n","type(pd_emotion_over_time) \n","pd_emotion_over_time.head()"]},{"cell_type":"code","execution_count":54,"id":"2e71c357","metadata":{},"outputs":[{"data":{"text/plain":["<AxesSubplot:xlabel='MONTH_YEAR', ylabel='TWEET_COUNT'>"]},"execution_count":54,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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\n","text/plain":["<Figure size 1080x576 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["import seaborn as sns\n","sns.set(rc = {'figure.figsize':(15,8)}) \n","sns.barplot(data=pd_emotion_over_time, x=\"MONTH_YEAR\", y=\"TWEET_COUNT\", hue = 'EMOTION')"]},{"cell_type":"code","execution_count":68,"id":"64a1d2fb","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["21/12/01 17:07:39 WARN org.apache.spark.deploy.yarn.YarnAllocator: Container from a bad node: container_1638368004038_0006_01_000019 on host: bigdatacluster2-w-0.us-west1-a.c.even-hull-328204.internal. Exit status: 143. Diagnostics: [2021-12-01 17:07:40.315]Container killed on request. Exit code is 143\n","[2021-12-01 17:07:40.315]Container exited with a non-zero exit code 143. \n","[2021-12-01 17:07:40.316]Killed by external signal\n",".\n","21/12/01 17:07:39 WARN org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 19 for reason Container from a bad node: container_1638368004038_0006_01_000019 on host: bigdatacluster2-w-0.us-west1-a.c.even-hull-328204.internal. Exit status: 143. Diagnostics: [2021-12-01 17:07:40.315]Container killed on request. Exit code is 143\n","[2021-12-01 17:07:40.315]Container exited with a non-zero exit code 143. \n","[2021-12-01 17:07:40.316]Killed by external signal\n",".\n","21/12/01 17:07:39 ERROR org.apache.spark.scheduler.cluster.YarnScheduler: Lost executor 19 on bigdatacluster2-w-0.us-west1-a.c.even-hull-328204.internal: Container from a bad node: container_1638368004038_0006_01_000019 on host: bigdatacluster2-w-0.us-west1-a.c.even-hull-328204.internal. Exit status: 143. Diagnostics: [2021-12-01 17:07:40.315]Container killed on request. Exit code is 143\n","[2021-12-01 17:07:40.315]Container exited with a non-zero exit code 143. \n","[2021-12-01 17:07:40.316]Killed by external signal\n",".\n","21/12/01 17:07:39 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 0.0 in stage 22.0 (TID 35) (bigdatacluster2-w-0.us-west1-a.c.even-hull-328204.internal executor 19): ExecutorLostFailure (executor 19 exited caused by one of the running tasks) Reason: Container from a bad node: container_1638368004038_0006_01_000019 on host: bigdatacluster2-w-0.us-west1-a.c.even-hull-328204.internal. Exit status: 143. Diagnostics: [2021-12-01 17:07:40.315]Container killed on request. Exit code is 143\n","[2021-12-01 17:07:40.315]Container exited with a non-zero exit code 143. \n","[2021-12-01 17:07:40.316]Killed by external signal\n",".\n","21/12/01 17:07:57 WARN org.apache.spark.deploy.yarn.YarnAllocator: Container from a bad node: container_1638368004038_0006_01_000020 on host: bigdatacluster2-w-1.us-west1-a.c.even-hull-328204.internal. Exit status: 143. Diagnostics: [2021-12-01 17:07:58.372]Container killed on request. Exit code is 143\n","[2021-12-01 17:07:58.372]Container exited with a non-zero exit code 143. \n","[2021-12-01 17:07:58.373]Killed by external signal\n",".\n","21/12/01 17:07:57 WARN org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 20 for reason Container from a bad node: container_1638368004038_0006_01_000020 on host: bigdatacluster2-w-1.us-west1-a.c.even-hull-328204.internal. Exit status: 143. Diagnostics: [2021-12-01 17:07:58.372]Container killed on request. Exit code is 143\n","[2021-12-01 17:07:58.372]Container exited with a non-zero exit code 143. \n","[2021-12-01 17:07:58.373]Killed by external signal\n",".\n","21/12/01 17:07:57 ERROR org.apache.spark.scheduler.cluster.YarnScheduler: Lost executor 20 on bigdatacluster2-w-1.us-west1-a.c.even-hull-328204.internal: Container from a bad node: container_1638368004038_0006_01_000020 on host: bigdatacluster2-w-1.us-west1-a.c.even-hull-328204.internal. Exit status: 143. Diagnostics: [2021-12-01 17:07:58.372]Container killed on request. Exit code is 143\n","[2021-12-01 17:07:58.372]Container exited with a non-zero exit code 143. \n","[2021-12-01 17:07:58.373]Killed by external signal\n",".\n","21/12/01 17:07:57 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 0.1 in stage 22.0 (TID 36) (bigdatacluster2-w-1.us-west1-a.c.even-hull-328204.internal executor 20): ExecutorLostFailure (executor 20 exited caused by one of the running tasks) Reason: Container from a bad node: container_1638368004038_0006_01_000020 on host: bigdatacluster2-w-1.us-west1-a.c.even-hull-328204.internal. Exit status: 143. Diagnostics: [2021-12-01 17:07:58.372]Container killed on request. Exit code is 143\n","[2021-12-01 17:07:58.372]Container exited with a non-zero exit code 143. \n","[2021-12-01 17:07:58.373]Killed by external signal\n",".\n","[Stage 24:===================>                                      (1 + 1) / 3]\r"]},{"name":"stdout","output_type":"stream","text":["+--------+--------------+-----------+\n","| EMOTION|tcountry_place|TWEET_COUNT|\n","+--------+--------------+-----------+\n","| sadness|            US|          3|\n","|    fear|            AU|          1|\n","|     joy|            IN|          3|\n","|     joy|            IE|          1|\n","|     joy|            DE|          1|\n","| sadness|            GB|          1|\n","|    fear|            US|          4|\n","|    fear|            JM|          1|\n","|    fear|            SG|          1|\n","|    fear|            CU|          2|\n","|    fear|            CA|          1|\n","|    fear|            GB|          1|\n","|surprise|            IN|          4|\n","| sadness|            IN|          3|\n","|surprise|            US|          5|\n","|     joy|            US|          2|\n","| sadness|            JM|          1|\n","|     joy|            GH|          1|\n","|    fear|            KE|          1|\n","|    fear|            CO|          1|\n","+--------+--------------+-----------+\n","only showing top 20 rows\n","\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["pd_emotion_by_country = spark.sql(\"SELECT EMOTION, tcountry_place, int(COUNT(*)) as TWEET_COUNT FROM\\\n","(SELECT * FROM vw_results WHERE tcountry_place <> 'NULL') a GROUP BY EMOTION, tcountry_place\")\n","\n","pd_emotion_by_country.show()"]},{"cell_type":"code","execution_count":43,"id":"4e1e2cfb","metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'pd_emotion_by_country' is not defined","output_type":"error","traceback":["\u001B[0;31m---------------------------------------------------------------------------\u001B[0m","\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)","\u001B[0;32m/tmp/ipykernel_8207/2005012169.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mpd_emotion_by_country\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpd_emotion_by_country\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtoPandas\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0mtype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpd_emotion_by_country\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0mpd_emotion_by_country\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mhead\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;31mNameError\u001B[0m: name 'pd_emotion_by_country' is not defined"]}],"source":["pd_emotion_by_country = pd_emotion_by_country.toPandas() \n","type(pd_emotion_by_country) \n","pd_emotion_by_country.head()"]},{"cell_type":"code","execution_count":null,"id":"df961c45","metadata":{},"outputs":[],"source":["import seaborn as sns\n","fig, ax = plt.subplots(figsize=(15,20))\n","sns.barplot(x= 'TWEET_COUNT', y='tcountry_place', hue='EMOTION', data = pd_emotion_by_country, ax=ax)"]}],"metadata":{"kernelspec":{"display_name":"PySpark","language":"python","name":"pyspark"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.12"}},"nbformat":4,"nbformat_minor":5}